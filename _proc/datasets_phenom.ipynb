{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: datasets_phenom.html\n",
    "title: datasets_phenom\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedb5e0",
   "metadata": {},
   "source": [
    "## Class constructor\n",
    "\n",
    "The class is initiated by accessing the `models_phenom` class and inspecting the available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd00c135",
   "metadata": {},
   "source": [
    "# `create_dataset`\n",
    "\n",
    "This function receives a list of dictionaries, each containing the properties of the trajectories to be created. The compulsory input for each dictionary is the key `model`, which defined the phenomenological diffusion model from which to create the trajectories. The rest of the properties are the ones of the model called. If no properties are given, the function automatically choses the default parameters of the model (check `models_phenom` for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662e5de",
   "metadata": {},
   "source": [
    "# `_create_trajectories`, `_save_trajectories`, `_load_trajectories`\n",
    "Auxiliary functions to `create_trajectories` that allow for creating, load and saving trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910bb7b-38be-4eb1-b00c-e12376b6da04",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dph = datasets_phenom()\n",
    "path = 'data/'\n",
    "\n",
    "main =  [{'model': 'dimerization', 'N': 40}\n",
    "        ]\n",
    "\n",
    "\n",
    "trajs, labels = dph.create_dataset(T = None, dics = main, N_model = None, path = path, load = False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433ac6d",
   "metadata": {},
   "source": [
    "# `_inspect_dic`\n",
    "Given a dictionary, this function checks that it fulfils the constraints of the program and checks the validity of the save/load actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48e4ce-68d8-44e6-8af9-7f2ab03b5bd0",
   "metadata": {},
   "source": [
    "# `_get_args`\n",
    "Given the name of a model, returns its input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c56280-9c97-45ca-aa74-2272deb1916e",
   "metadata": {},
   "source": [
    "# Challenge 2022 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d934936-9348-45d1-8e4c-3e396a1a1a8a",
   "metadata": {},
   "source": [
    "## Default challenge parameters\n",
    "This function generates dictionaries of plausible parameters for each experiment. We start with the following groudbase values:\n",
    "\n",
    "\n",
    "- Fielf of view (fov): $128 x 128 px^2$, with a pixel size of 100 nm, for a size of the box $FOV=12.8 \\ \\mu m$. We will simulate trajectories in a box of $L = 2*FOV$ and the only considers segments inside the fov. This allows to eliminate problems with boundaries.\n",
    "- Frame rate $= 0.1 Hz$, i.e. $\\Delta t = 100 \\ ms  = 0.1 \\ s$ .\n",
    "- Typical $D = 0.01 \\ \\mu m^2/s$. To calculate the input of the program, we need to consider the following:\n",
    "    - As a working definition of $D$, valid also for anomalous diffusion, we consider it as proporcional to the variance of the displacements along one dimension at the shortest time lag, i.e. $\\sigma_{\\Delta x}^2= 2  D \\Delta t $\n",
    "    - Given the values of pixel size and frame rate, in adimensional unit $D$ is given by: $D= 0.01 \\ \\frac{\\mu m^2}{s} \\ \\frac{0.1 s/ \\Delta t }{  0.01 \\mu m^2/px^2} = 0.1 px^2/\\Delta t $ .\n",
    "    - Localization precision $\\sigma_{x} = 12 \\ nm = \\frac{12 \\ nm} {100 \\ nm/px}  = 0.12 \\ px$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbe77b-32d9-4a4f-a67a-3f4cb21b7fef",
   "metadata": {},
   "source": [
    "### `get_dic_andi2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324074f8-432e-464c-b85d-9fbcff852ef0",
   "metadata": {},
   "source": [
    "## Generating function\n",
    "This function generates trajectory datasets like the ones considered in the ANDI 2022 Challenge. It is based in `models_phenom.create_dataset` but also applies:\n",
    "\n",
    "- Apply Field of View (FOV)\n",
    "- Add localization noise\n",
    "- Smooth labels\n",
    "- Extracts ensemble properties\n",
    "- Correct labeling of trajectories\n",
    "\n",
    "\n",
    "**Inputs:**\n",
    "- Number of experiments (one experiment = one model).\n",
    "\n",
    "    For each experiment:\n",
    "    - Number of particles\n",
    "    - Number of FOVs\n",
    "    - Parameters of the model\n",
    "    - Mininum length of trajectories\n",
    "    \n",
    "**Outputs:** (this should be the same as the expected challenge inputs)\n",
    "    \n",
    "- For each FOV:\n",
    "    - Ensemble properties (Compulsory: model, $\\alpha$ and $D$ distribution)\n",
    "    - Trajectory properties (list of properties: $\\alpha_1$, $D_1$, CP$_1$, $\\alpha_2$, $D_2$, CP$_2$,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### datasets_phenom\n",
       "\n",
       ">      datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n",
       ">                       object at 0x00000292937454B0>)\n",
       "\n",
       "Constructor of the class"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(datasets_phenom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ebbd5-ade4-4afa-a435-1db6068a4d87",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6bd47fc6b14d858f793d2ac379c798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dph \u001b[38;5;241m=\u001b[39m datasets_phenom()\n\u001b[0;32m      2\u001b[0m num_experiments, num_fovs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df_list, lab_t, lab_e \u001b[38;5;241m=\u001b[39m \u001b[43mdph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchallenge_2022_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_experiments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mnum_fovs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_fovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mreturn_timestep_labs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mrepeat_exp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mdatasets_phenom.challenge_2022_dataset\u001b[1;34m(self, experiments, dics, repeat_exp, num_fovs, return_timestep_labs, save_data, path, prefix)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Overide the info about model\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavail_models_name\u001b[38;5;241m.\u001b[39mindex(dic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 102\u001b[0m trajs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Add noise the trajectories\u001b[39;00m\n\u001b[0;32m    105\u001b[0m trajs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39mtrajs\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df_andi2()\u001b[38;5;241m.\u001b[39msigma_noise    \n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mdatasets_phenom.create_dataset\u001b[1;34m(self, dics, T, N_model, path, save, load)\u001b[0m\n\u001b[0;32m     51\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath) \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m'''Create trajectories'''\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m trajs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trajs, labels\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mdatasets_phenom._create_trajectories\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create dictionary with only arguments\u001b[39;00m\n\u001b[0;32m     22\u001b[0m dic_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dic); dic_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m trajs, labels \u001b[38;5;241m=\u001b[39m model_f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdic_args)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Save the trajectories if asked\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave:\n",
      "File \u001b[1;32mc:\\users\\gorka\\github\\andi_datasets\\andi_datasets\\models_phenom.py:1067\u001b[0m, in \u001b[0;36mmodels_phenom.confinement\u001b[1;34m(self, N, T, Ds, alphas, gamma_d, epsilon_a, L, deltaT, r, comp_center, Nc, trans)\u001b[0m\n\u001b[0;32m   1060\u001b[0m alphas_traj, Ds_traj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_diff_parameters(alphas \u001b[38;5;241m=\u001b[39m alphas,\n\u001b[0;32m   1061\u001b[0m                                                     Ds \u001b[38;5;241m=\u001b[39m Ds,\n\u001b[0;32m   1062\u001b[0m                                                     num_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1063\u001b[0m                                                     epsilon_a \u001b[38;5;241m=\u001b[39m epsilon_a,\n\u001b[0;32m   1064\u001b[0m                                                     gamma_d \u001b[38;5;241m=\u001b[39m gamma_d)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Get trajectory from single traj function\u001b[39;00m\n\u001b[1;32m-> 1067\u001b[0m pos, lab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_confinement_traj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mDs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDs_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malphas_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdeltaT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeltaT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcomp_center\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcomp_center\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1076\u001b[0m data[:, n, :] \u001b[38;5;241m=\u001b[39m pos\n\u001b[0;32m   1077\u001b[0m labels[:, n, :] \u001b[38;5;241m=\u001b[39m lab\n",
      "File \u001b[1;32mc:\\users\\gorka\\github\\andi_datasets\\andi_datasets\\models_phenom.py:1023\u001b[0m, in \u001b[0;36mmodels_phenom._confinement_traj\u001b[1;34m(T, Ds, alphas, L, deltaT, r, comp_center, Nc, trans)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# Define state of particles based on the state array. First free/directed\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alphas[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m models_phenom()\u001b[38;5;241m.\u001b[39malpha_directed:\n\u001b[1;32m-> 1023\u001b[0m     labels[state \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m models_phenom()\u001b[38;5;241m.\u001b[39mlab_state\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     labels[state \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m models_phenom()\u001b[38;5;241m.\u001b[39mlab_state\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dph = datasets_phenom()\n",
    "num_experiments, num_fovs = 5, 5\n",
    "df_list, lab_t, lab_e = dph.challenge_2022_dataset(experiments = num_experiments,\n",
    "                                                   num_fovs = num_fovs, \n",
    "                                                   return_timestep_labs=True, \n",
    "                                                   repeat_exp = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d8b32-d6f4-457a-a5ce-041e07478675",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b848055d2c46468c6a95284a1745da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dph = datasets_phenom()\n",
    "num_experiments = 1\n",
    "dic = dph._get_dic_andi2(3)\n",
    "    \n",
    "df_list, lab_t, lab_e = dph.challenge_2022_dataset(save_data = False,\n",
    "                                                   dics = [dic],\n",
    "                                                   num_fovs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1969e0e",
   "metadata": {},
   "source": [
    "# NBDEV Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4eb709-6e09-409a-a2f8-6546bdfd8b95",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc036d0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
