[
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "analysis",
    "section": "",
    "text": "MSD based analysis\n\n\nmsd_analysis\n\n msd_analysis ()\n\nContains mean squared displacement (MSD) based methods to analyze trajectories.\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns \n---------- in \nCalculates the time average mean squared displacement (TA-MSD) of a trajectory at various time lags,\n...\n  else: warn(msg)\n\n\n\nmsd_analysis.tamsd\n\n msd_analysis.tamsd (traj:numpy.ndarray, t_lags:numpy.ndarray)\n\nCalculates the time average mean squared displacement (TA-MSD) of a trajectory at various time lags,\n\n\n\n\nType\nDetails\n\n\n\n\ntraj\nndarray\nTrajectory from whicto calculate TA-MSD.\n\n\nt_lags\nndarray\nTime lags used for the TA-MSD\n\n\nReturns\nnp.array\nTA-MSD of the given trayectory\n\n\n\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns \n---------- in \nCalculates the diffusion coefficient of a trajectory by means of the linear\nfitting of the TA-MSD....\n  else: warn(msg)\n\n\n\nmsd_analysis.get_diff_coeff\n\n msd_analysis.get_diff_coeff (traj:numpy.ndarray,\n                              t_lags:bool|list|numpy.ndarray=None)\n\nCalculates the diffusion coefficient of a trajectory by means of the linear fitting of the TA-MSD.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntraj\nndarray\n\n1D trajectory from whicto calculate TA-MSD.\n\n\nt_lags\nbool | list | numpy.ndarray\nNone\nTime lags used for the TA-MSD.\n\n\nReturns\nnp.array\n\nDiffusion coefficient of the given trajectory. \n\n\n\nHere we show an example for the calculation of a Brownian motion trajectory. We create 100 trajectories from displacements of variance \\(\\sigma =1\\), which results in a diffusion coefficient \\(D=0.5\\).\n\nD = []\nfor _ in range(1000):    \n    pos = np.cumsum(np.random.randn(100))\n    D.append(msd_analysis().get_diff_coeff(pos))\n    \nplt.hist(D, bins = 30);\nplt.axvline(np.mean(D), c = 'k', label = f'Mean of predictions = {np.round(np.mean(D), 2)}')                                                                  \nplt.axvline(0.5, c = 'r', ls = '--', label = 'Expected')\nplt.legend()\n\n<matplotlib.legend.Legend>\n\n\n\n\n\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns \n---------- in \nCalculates the anolaous of a trajectory by means of the linear\nfitting of the logarithm of the TA-MSD....\n  else: warn(msg)\n\n\n\nmsd_analysis.get_exponent\n\n msd_analysis.get_exponent (traj:numpy.ndarray,\n                            t_lags:bool|list|numpy.ndarray=None)\n\nCalculates the anolaous of a trajectory by means of the linear fitting of the logarithm of the TA-MSD.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntraj\nndarray\n\n1D trajectory from whicto calculate TA-MSD.\n\n\nt_lags\nbool | list | numpy.ndarray\nNone\nTime lags used for the TA-MSD.\n\n\nReturns\nnp.array\n\nAnomalous exponent of the given trajectory. \n\n\n\nTo showcase this function, we generate fractional brownian motion trajectories with \\(\\alpha = 0.5\\) and calculate their exponent:\n\nalpha = []\ntrajs, _ = models_phenom().single_state(N = 1000, T = 100, alphas = 0.5) \nfor traj in trajs.transpose(1,0,2):    \n    alpha.append(msd_analysis().get_exponent(traj[:,0]))\n    \nplt.hist(alpha, bins = 30);\nplt.axvline(np.mean(alpha), c = 'k', label = f'Mean of predictions = {np.round(np.mean(alpha), 2)}')\nplt.axvline(0.5, c = 'r', ls = '--', label = 'Expected')\nplt.legend()\n\n<matplotlib.legend.Legend>\n\n\n\n\n\n\n\n\nVelocity Autocorrelation Function (VACF)\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns \n---------- in \nCalculates the velocity autocorrelation function for \nthe given set of trajectories....\n  else: warn(msg)\n\n\nvacf\n\n vacf (trajs, delta_t:int|list|numpy.ndarray=1,\n       taus:bool|list|numpy.ndarray=None)\n\nCalculates the velocity autocorrelation function for the given set of trajectories.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrajs\nnp.array\n\nNxT matrix containing N trajectories of length T.\n\n\ndelta_t\nint | list | numpy.ndarray\n1\nIf not None, the vacf is calculated in the demanded time lags.\n\n\ntaus\nbool | list | numpy.ndarray\nNone\nTime windows at wich the vacf is calculated.\n\n\nReturns\nnp.array\n\nVACF of the given trajectories and the given time windows. \n\n\n\nWe show here an example of the VACF for FBM trajectories at various time lages, showing that they all coincide (as expected for this diffusion model).\n\ndeltats = np.arange(1, 5).tolist()\ntaus = np.arange(0, 100)\ntrajs, _ = models_phenom().single_state(N = 200, T = 200, alphas = 0.5)\ntrajs = trajs.transpose(1, 0, 2)[:,:,0]\n\nfor deltat in deltats:  \n    v = vacf(trajs, deltat, taus)        \n    plt.plot(taus/deltat, v.flatten(), 'o-', alpha = 0.4)    \nplt.xlim(-1, 10)\nplt.ylabel('VACF'); plt.xlabel(r'$\\tau / \\delta$')\n\nText(0.5, 0, '$\\\\tau / \\\\delta$')\n\n\n\n\n\n\n\n\nConvex hull analysis\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns \n---------- in \nComputes the changes points a multistate trajectory based on the Convex Hull approach proposed in PRE 96 (022144), 2017.\n...\n  else: warn(msg)\n\n\nCH_changepoints\n\n CH_changepoints (trajs, tau:int=10, metric:{'volume','area'}='volume')\n\nComputes the changes points a multistate trajectory based on the Convex Hull approach proposed in PRE 96 (022144), 2017.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrajs\nnp.array\n\nNxT matrix containing N trajectories of length T.\n\n\ntau\nint\n10\nTime window over which the CH is calculated.\n\n\nmetric\n{‘volume’, ‘area’}\nvolume\nCalculate change points w.r.t. area or volume of CH.\n\n\nReturns\nlist\n\nChange points of the given trajectory.\n\n\n\nWe showcase the use of the convex hull in a Brownian motion trajectory with two distinct diffusion coefficients, one 10 times the other:\n\n# Generate trajectories and plot change points\nT = 100; on = 40; off = 60;\ntraj = np.random.randn(T, 2)\ntraj[on:off, :] = traj[on:off, :]*10\ntraj = traj.cumsum(0)\nplt.axvline(on-tau, c = 'k')\nplt.axvline(off-tau, c = 'k', label = 'True change points')\n\n# Calculate variable Sd \ntau = 5\nSd = np.zeros(traj.shape[0]-2*tau)\nfor k in range(traj.shape[0]-2*tau):       \n    Sd[k] = ConvexHull(traj[k:(k+2*tau)], ).volume  \n\n# Compute change points both with volume and area\nCPs = CH_changepoints([traj], tau = tau)[0].flatten()-tau\nCPs_a = CH_changepoints([traj], tau = tau, metric = 'area')[0].flatten()-tau\n\n\n# Plot everything\nlabel_cp = 'CH Volume'\nfor cp in CPs:\n    plt.axvline(cp, c = 'g', alpha = 0.8, ls = '--', label = label_cp)\n    label_cp = ''\nlabel_cp = 'CH Area'    \nfor cp in CPs_a:\n    plt.axvline(cp, alpha = 0.8, ls = '--', c = 'orange', label = label_cp)\n    label_cp = ''\n    \nplt.plot(Sd, '-o')\nplt.axhline(Sd.mean(), label = 'CH Volume mean', c = 'g',)\nplt.legend()\nplt.xlabel('n'); plt.ylabel(r'$S_d(n)$')\n\nText(0, 0.5, '$S_d(n)$')"
  },
  {
    "objectID": "datasets_challenge.html",
    "href": "datasets_challenge.html",
    "title": "datasets_challenge",
    "section": "",
    "text": "C:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nOutputs \n-------- in \nCreates a dataset similar to the one given by in the ANDI challenge. \nCheck the webpage of the challenge for more details. The default values...\n  else: warn(msg)\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: Unknown section Inputs\n  else: warn(msg)\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: Unknown section Outputs\n  else: warn(msg)\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n\n\n\n\n challenge_2020_dataset (N:numpy.ndarray|int=1000, max_T:int=1000,\n                         min_T:int=10, tasks:list|int=[1, 2, 3],\n                         dimensions:list|int=[1, 2, 3],\n                         load_dataset:{'False','True'}=False,\n                         save_dataset:{'False','True'}=False,\n                         path_datasets:str='',\n                         load_labels:{'False','True'}=True,\n                         load_trajectories:{'False','True'}=False,\n                         save_trajectories:{'False','True'}=False,\n                         path_trajectories:str='datasets/',\n                         N_save:int=1000, t_save:int=1000,\n                         return_noise:{'False','True'}=False)\n\nCreates a dataset similar to the one given by in the ANDI challenge. Check the webpage of the challenge for more details. The default values are similar to the ones used to generate the available dataset.\nThe function returns 6 variables, three variables for the trajectories and three for the corresponding labels. Each variable is a list of three lists. Each of the three lists corresponds to a given dimension, in ascending order. If one of the tasks/dimensions was not calculated, the given list will be empty.\nSee the tutorials in our Github repository to learn about this function."
  },
  {
    "objectID": "datasets_challenge.html#test",
    "href": "datasets_challenge.html#test",
    "title": "datasets_challenge",
    "section": "Test",
    "text": "Test\n\nDistributions parameters\n\nnum_experiments, num_fovs = 5, 1\n\ndics = []\nfor i in range(num_experiments):    \n    dic = _get_dic_andi2(i+1)    \n    dics.append(dic)\n    \ndf_list, _, _ = challenge_2022_dataset(experiments = num_experiments, \n                                       num_fovs = num_fovs, \n                                       dics = dics,\n                                       return_timestep_labs = True\n                                              )\n\n\n\n\n\nfig, axs = plt.subplots(2, len(df_list), figsize = (len(df_list)*2, 2*2), tight_layout = True)\n\nfor df, ax, dic in zip(df_list, axs.transpose(), dics):\n    alphas = df['alpha']\n    Ds = df['D']\n    states = df['state']\n    for u in np.unique(states):\n        ax[0].hist(alphas[states == u], density = 1)\n        ax[1].hist(Ds[states == u], density = 1)\n    \n    ax[0].set_title(dic['model'])\nplt.setp(axs[:,0], ylabel = 'Frequency')\nplt.setp(axs[0,:], xlabel = r'$\\alpha$')\nplt.setp(axs[1,:], xlabel = r'$D$')\n;\n\n''\n\n\n\n\n\n\n\nFOVs\n\nnum_fovs = 3\ndf_fov, _ , lab_e = challenge_2022_dataset(experiments = [1,2,3,4,5],\n                                           num_fovs =num_fovs, \n                                           return_timestep_labs = True\n                                           )"
  },
  {
    "objectID": "datasets_phenom.html",
    "href": "datasets_phenom.html",
    "title": "datasets_phenom",
    "section": "",
    "text": "datasets_phenom\n\n datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n                  object at 0x0000021637E7A0E0>)\n\nThis class generates, saves and loads datasets of trajectories simulated from various phenomenological diffusion models (available at andi_datasets.models_phenom).\n\n\n\ndatasets_phenom.create_dataset\n\n datasets_phenom.create_dataset (dics=False, T=None, N_model=None,\n                                 path='', save=False, load=False)\n\nGiven a list of dictionaries, generates trajectories of the demanded properties. The only compulsory input for every dictionary is ‘model’, i.e. the model from which trajectories must be generated. The rest of inputs are optional. You can see the input parameters of the different models in andi_datasets.models_phenom, This function checks and handles the input dataset and the manages both the creation, loading and saving of trajectories.\nIn the example below we create two dictionaries and generate a dataset with it. See the corresponding tutorial for more details.\n\nfrom andi_datasets.datasets_phenom import datasets_phenom\nfrom andi_datasets.utils_trajectories import plot_trajs\n\n\nL = 50\ndict_model3 = {'model': 'dimerization', \n               'L': L,\n               'Pu': 0.1, 'Pb': 1}\ndict_model5 = {'model': 'confinement',\n               'L': L, \n               'trans': 0.2}\n\ndict_all = [dict_model3, dict_model5]\n\ntrajs, labels = datasets_phenom().create_dataset(N_model = 10, # number of trajectories per model\n                                                 T = 200,\n                                                 dics = dict_all\n                                                )\nplot_trajs(trajs, L , 10, \n           num_to_plot = 3,\n           labels = labels,\n           plot_labels = True\n          )\n\n\n\n\n\n\nCreating, saving and loading trajectories\nThese auxiliary functions used in create_trajectories that allow for manipulate trajectories in various forms.\n\n\ndatasets_phenom._create_trajectories\n\n datasets_phenom._create_trajectories ()\n\nGiven a list of dictionaries, generates trajectories of the demanded properties. First checks in the .csv of each demanded model if a dataset of similar properties exists. If it does, it loads it from the corresponding file.\n\n\n\ndatasets_phenom._save_trajectories\n\n datasets_phenom._save_trajectories (trajs, labels, dic, df, dataset_idx,\n                                     path)\n\nGiven a set of trajectories and labels, saves two things:\n\nIn the .csv corresponding to the demanded model, all the input parameters of the generated dataset.\nIn a .npy file, the trajectories and labels generated.\n\n\n\n\ndatasets_phenom._load_trajectories\n\n datasets_phenom._load_trajectories (model_name, dataset_idx, path)\n\nGiven the path for a dataset, loads the trajectories and labels\n\n\n\nManaging parameters and dictionaries\n\n\ndatasets_phenom._inspect_dic\n\n datasets_phenom._inspect_dic (dic)\n\nChecks the information of the input dictionaries, complete missing information with default values and then decides about loading/saving depending on parameters.\n\n\n\ndatasets_phenom._get_args\n\n datasets_phenom._get_args (model, return_defaults=False)\n\nGiven the name of a diffusion model, return its inputs arguments."
  },
  {
    "objectID": "datasets_phenom.html#default-challenge-parameters",
    "href": "datasets_phenom.html#default-challenge-parameters",
    "title": "datasets_phenom",
    "section": "Default challenge parameters",
    "text": "Default challenge parameters\nThis function generates dictionaries of plausible parameters for each experiment. We start with the following groudbase values:\n\nFielf of view (fov): \\(128 x 128 px^2\\), with a pixel size of 100 nm, for a size of the box \\(FOV=12.8 \\ \\mu m\\). We will simulate trajectories in a box of \\(L = 2*FOV\\) and the only considers segments inside the fov. This allows to eliminate problems with boundaries.\nFrame rate \\(= 0.1 Hz\\), i.e. \\(\\Delta t = 100 \\ ms = 0.1 \\ s\\) .\nTypical \\(D = 0.01 \\ \\mu m^2/s\\). To calculate the input of the program, we need to consider the following:\n\nAs a working definition of \\(D\\), valid also for anomalous diffusion, we consider it as proporcional to the variance of the displacements along one dimension at the shortest time lag, i.e. $_{x}^2= 2 D t $\nGiven the values of pixel size and frame rate, in adimensional unit \\(D\\) is given by: $D= 0.01     = 0.1 px^2/t $ .\nLocalization precision \\(\\sigma_{x} = 12 \\ nm = \\frac{12 \\ nm} {100 \\ nm/px} = 0.12 \\ px\\).\n\n\n\n\ndatasets_phenom\n\n datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n                  object at 0x00000216348BC460>)\n\nConstructor of the class\n\n\nget_dic_andi2\n\n\n\ndatasets_phenom\n\n datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n                  object at 0x00000216348BC460>)\n\nConstructor of the class"
  },
  {
    "objectID": "datasets_phenom.html#generating-function",
    "href": "datasets_phenom.html#generating-function",
    "title": "datasets_phenom",
    "section": "Generating function",
    "text": "Generating function\nThis function generates trajectory datasets like the ones considered in the ANDI 2022 Challenge. It is based in models_phenom.create_dataset but also applies:\n\nApply Field of View (FOV)\nAdd localization noise\nSmooth labels\nExtracts ensemble properties\nCorrect labeling of trajectories\n\nInputs: - Number of experiments (one experiment = one model).\nFor each experiment:\n- Number of particles\n- Number of FOVs\n- Parameters of the model\n- Mininum length of trajectories\nOutputs: (this should be the same as the expected challenge inputs)\n\nFor each FOV:\n\nEnsemble properties (Compulsory: model, \\(\\alpha\\) and \\(D\\) distribution)\nTrajectory properties (list of properties: \\(\\alpha_1\\), \\(D_1\\), CP\\(_1\\), \\(\\alpha_2\\), \\(D_2\\), CP\\(_2\\),…)\n\n\n\n\ndatasets_phenom\n\n datasets_phenom (models_class=<andi_datasets.models_phenom.models_phenom\n                  object at 0x00000216348BC460>)\n\nConstructor of the class\n\ndph = datasets_phenom()\nnum_experiments, num_fovs = 5, 5\ndf_list, lab_t, lab_e = dph.challenge_2022_dataset(experiments = num_experiments,\n                                                   num_fovs = num_fovs, \n                                                   return_timestep_labs=True, \n                                                   repeat_exp = False)\n\n\n\n\nKeyboardInterrupt: \n\n\n\ndph = datasets_phenom()\nnum_experiments = 1\ndic = dph._get_dic_andi2(3)\n    \ndf_list, lab_t, lab_e = dph.challenge_2022_dataset(save_data = False,\n                                                   dics = [dic],\n                                                   num_fovs = 1)"
  },
  {
    "objectID": "datasets_theory.html",
    "href": "datasets_theory.html",
    "title": "Datasets of theoretical trajectories",
    "section": "",
    "text": "datasets_theory\n\n datasets_theory ()\n\nThis class generates, saves and loads datasets of theoretical trajectories simulated from various diffusion models (available at andi_datasets.models_theory).\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: potentially wrong underline length... \nInputs \n-------- in \nCreates a dataset of trajectories via the theoretical models defined in `.models_theory`. Check our tutorials for use cases of this function.\n...\n  else: warn(msg)\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: Unknown section Inputs\n  else: warn(msg)\n\n\n\ndatasets_theory.create_dataset\n\n datasets_theory.create_dataset (T, N_models, exponents, models,\n                                 dimension=1, save_trajectories=False,\n                                 load_trajectories=False,\n                                 path='datasets/', N_save=1000,\n                                 t_save=1000)\n\nCreates a dataset of trajectories via the theoretical models defined in .models_theory. Check our tutorials for use cases of this function.\nC:\\Users\\Gorka\\Anaconda3\\envs\\andi_dataset\\lib\\site-packages\\fastcore\\docscrape.py:225: UserWarning: Unknown section Arguments\n  else: warn(msg)\n\n\n\ndatasets_theory.create_segmented_dataset\n\n datasets_theory.create_segmented_dataset (dataset1, dataset2,\n                                           dimension=1, final_length=200,\n                                           random_shuffle=False)\n\nCreates a dataset with trajectories which change diffusive feature (either model or anomalous exponent) after a time ‘t_change’.\n\n\n\ndatasets_theory.create_noisy_diffusion_dataset\n\n datasets_theory.create_noisy_diffusion_dataset (dataset=False, T=False,\n                                                 N=False, exponents=False,\n                                                 models=False,\n                                                 dimension=1, diffusion_co\n                                                 efficients=False,\n                                                 save_trajectories=False,\n                                                 load_trajectories=False,\n                                                 path='datasets/',\n                                                 N_save=1000, t_save=1000)\n\nCreate a dataset of noisy trajectories. This function creates trajectories with _create_trajectories and then adds given noise to them."
  },
  {
    "objectID": "models_phenom.html",
    "href": "models_phenom.html",
    "title": "models_phenom",
    "section": "",
    "text": "models_phenom ()\n\nConstructor of the class"
  },
  {
    "objectID": "models_phenom.html#single-trajectory-generator",
    "href": "models_phenom.html#single-trajectory-generator",
    "title": "models_phenom",
    "section": "Single trajectory generator",
    "text": "Single trajectory generator\nInput: - \\(T\\): (scalar) Length of the trajectory - \\(D\\): (scalar) Diffusion coefficient (defined as the square root of the standard deviation of the displacements). - \\(\\alpha\\): (scalar) anomalous exponent. - \\(L\\): (scalar) size of the squared box acting as environment. If None, the system is infinite.\nOutput: - pos: (array of size \\(T\\times 2\\)) Position of the particle at each timestep. - labels: (array of size \\(T\\times 3\\)) Anomalous exponent, D and state at each timestep. In this case, the state is alway ‘free’.\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\ntraj, labels = models_phenom._single_state_traj(D = 0.05, T =1000, alpha = 1.98, L = 10)\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 7.5), tight_layout = True)\nax[0].plot(traj[:, 0], traj[:, 1], alpha = 0.5)\nplt.setp(ax[0], xlabel = 'X', ylabel = 'Y')\nax[0].axhline(10, ls = '--', alpha = 0.3, c = 'k')\nax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\nax[0].axvline(10, ls = '--', alpha = 0.3, c = 'k')\nax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n\nax[1].plot(traj[:, 0], '.', label = 'X')\nax[1].plot(traj[:, 1], '.', label = 'Y', )\nplt.setp(ax[1], ylabel = 'Position', xlabel = 'Time')\nax[1].axhline(10, ls = '--', alpha = 0.3, c = 'k')\nax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\nax[1].legend()\n\nax[2].plot(labels[:, 0], '.', label = r'$\\alpha$')\nax[2].plot(labels[:, 1], '.', label = r'$D$' )\nplt.setp(ax[2], ylabel = 'Label', xlabel = 'Time')\nax[2].legend()\n\n<matplotlib.legend.Legend>"
  },
  {
    "objectID": "models_phenom.html#dataset-generation",
    "href": "models_phenom.html#dataset-generation",
    "title": "models_phenom",
    "section": "Dataset generation",
    "text": "Dataset generation\nInput: - \\(N\\): (scalar) Number of trajectories in the dataset - \\(T\\): (scalar) Length of the trajectory - \\(D\\): (scalar) Diffusion coefficient (defined as the square root of the standard deviation of the displacements). - \\(\\alpha\\): (scalar) anomalous exponent. - \\(L\\): (scalar) size of the squared box acting as environment. If None, the system is infinite.\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 500; L = 5; T = 100;\nalpha = [0.8, 0.1]; D = 1.2\n\ntrajs, labels = models_phenom().single_state(N = N,\n                                           L = L,\n                                           T = T, \n                                           alphas = alpha,\n                                           Ds = D)\n\n\nfig, ax = plt.subplots()\nax.hist(labels[0,:,0])\nplt.setp(ax, title = r'Distribution of $\\alpha$', xlabel = r'$\\alpha$', ylabel = 'Frequency');\n\n\n\n\n\nfig, axs = plt.subplots(3, 4, figsize = (15, 7.5), tight_layout = True)\n\nfor ax in axs.transpose():\n    part = np.random.randint(N)    \n    ax[0].set_title(f'Particle # {part}')\n    ax[0].plot(trajs[:, part, 0], trajs[:, part, 1], alpha = 0.5)\n    ax[0].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[1].plot(trajs[:, part, 0], 'o-', label = 'X', ms = 3, lw = 0.1)\n    ax[1].plot(trajs[:, part, 1], 'o-', label = 'Y', ms = 3, lw = 0.1)\n    ax[1].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[2].plot(labels[:, part, 0], 'o-', label = r'$\\alpha$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 1], 'o-', label = r'$D$', ms = 3, lw = 0.1)\n\n\nplt.setp(axs[0, :], xlabel = 'X', ylabel = 'Y')\n\naxs[1, 0].legend()\nplt.setp(axs[1, 0], ylabel = 'Position')\nplt.setp(axs[1, :], xticklabels = '')\n\naxs[2, 0].legend()\nplt.setp(axs[2, 0], ylabel = 'Labels')\nplt.setp(axs[2, :], xlabel = 'Time');"
  },
  {
    "objectID": "models_phenom.html#single-trajectory-generator-1",
    "href": "models_phenom.html#single-trajectory-generator-1",
    "title": "models_phenom",
    "section": "Single trajectory generator",
    "text": "Single trajectory generator\nInput: - \\(T\\): (scalar) lenght of the trajectory - \\(M\\): (matrix) Transition matrix stating the probability of switching between states at each time step. - \\(D\\)s: (scalar or vector) diffusion coefficient of each state. If scalar, all segments have same value. - \\(\\alpha\\)s (alphas): (scalar or vector) anomalous exponent of each state. If scalar, all segments have same value. - \\(L\\): (scalar) size of the squared box acting as environment. If None, the system is infinite.\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nT = 1000; L = 100\nX = models_phenom._multiple_state_traj(T = T,\n                                       L = L,\n                                       alphas = [0.7, 1.98], Ds = [0, 1], return_state_num=True)\n\n\ntraj = X[0]; labels = X[1]\n# traj, labels = multiple_states(T = 1000,\n#                            L = 10,\n#                            M = np.array([[0.8 , 0.1, 0.1],[0.01, 0.98, 0.01],[0, 0.05 ,0.95]]),\n#                            alphas = [0.8, 1.2, 1.4],\n#                            Ds = [1, 0, 2])\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 7.5), tight_layout = True)\nax[0].plot(traj[:, 0], traj[:, 1], alpha = 0.5)\nplt.setp(ax[0], xlabel = 'X', ylabel = 'Y')\nax[0].axhline(L, ls = '--', alpha = 0.3, c = 'k')\nax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\nax[0].axvline(L, ls = '--', alpha = 0.3, c = 'k')\nax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n\nax[1].plot(traj[:, 0], '.', label = 'X')\nax[1].plot(traj[:, 1], '.', label = 'Y', )\nplt.setp(ax[1], ylabel = 'Position', xlabel = 'Time')\nax[1].axhline(L, ls = '--', alpha = 0.3, c = 'k')\nax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\nax[1].legend()\n\nax[2].plot(labels[:, 0], '.', label = r'$\\alpha$')\nax[2].plot(labels[:, 1], '.', label = r'$D$' )\nax[2].plot(labels[:, 2], '.', label = r'$state$', alpha = 0.3 )\n\nplt.setp(ax[2], ylabel = 'Label', xlabel = 'Time')\nax[2].legend()\n\nAttributeError: 'models_phenom' object has no attribute 'disp_fbm'"
  },
  {
    "objectID": "models_phenom.html#dataset-generation-1",
    "href": "models_phenom.html#dataset-generation-1",
    "title": "models_phenom",
    "section": "Dataset generation",
    "text": "Dataset generation\nInput: - \\(N\\): (scalar) Number of trajectories in the dataset - Inputs of multiple_states\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 1000; L = 50; T = 10;\n\ntrajs, labels = models_phenom().multi_state(N = N,\n                                       T = T,\n                                       L = L,\n                                       M = np.array([[0.95 , 0.05],[0.01, 0.99]]),\n                                        Ds = np.array([[1, 0], [0.5, 0.01]]), \n                                        alphas = np.array([[1, 0.01], [0.5, 0.02]]),\n                                            epsilon_a=[0.4], gamma_d = [0.2],\n                                                      return_state_num=True)\n\n\nfig, ax = plt.subplots()\nax.hist(labels[:,:,1].flatten())\nplt.setp(ax, title = r'Distribution of $D$', xlabel = r'$D$', ylabel = 'Frequency');\n\n\n\n\n\nfig, ax = plt.subplots()\nax.hist(labels[:,:,0].flatten(), bins = 20)\nplt.setp(ax, title = r'Distribution of $\\alpha$', xlabel = r'$\\alpha$', ylabel = 'Frequency');\n\n\n\n\n\nfig, axs = plt.subplots(3, 4, figsize = (15, 7.5), tight_layout = True)\n\nfor ax in axs.transpose():\n    part = np.random.randint(N)    \n    ax[0].set_title(f'Particle # {part}')\n    ax[0].plot(trajs[:, part, 0], trajs[:, part, 1], alpha = 0.5)\n    ax[0].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[1].plot(trajs[:, part, 0], 'o-', label = 'X', ms = 3, lw = 0.1)\n    ax[1].plot(trajs[:, part, 1], 'o-', label = 'Y', ms = 3, lw = 0.1)\n    ax[1].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[2].plot(labels[:, part, 0], 'o-', label = r'$\\alpha$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 1], 'o-', label = r'$D$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, -1], 'o-', label = r'$D$', ms = 3, lw = 0.1, alpha = 0.3)\n\n\nplt.setp(axs[0, :], xlabel = 'X', ylabel = 'Y')\n\naxs[1, 0].legend()\nplt.setp(axs[1, 0], ylabel = 'Position')\nplt.setp(axs[1, :], xticklabels = '')\n\naxs[2, 0].legend()\nplt.setp(axs[2, 0], ylabel = 'Labels')\nplt.setp(axs[2, :], xlabel = 'Time');"
  },
  {
    "objectID": "models_phenom.html#auxiliary-functions",
    "href": "models_phenom.html#auxiliary-functions",
    "title": "models_phenom",
    "section": "Auxiliary functions",
    "text": "Auxiliary functions\nDistance calculator\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\nEscaping dynamics\n\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\nClustering dynamics\n\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 200; L = 10; r = 1; max_n = 2; Ds = np.ones(100)\n\npos = np.random.rand(N, 2)*L    \nlabel = np.random.choice(range(500), N, replace = False)\nmax_label = max(label+2)\ndistance = models_phenom._get_distance(pos)\ndiff_state = np.zeros(N).astype(int)\n\nl, d = models_phenom._make_condensates(0.01, label, diff_state, r, distance, max_label)\nle, de = models_phenom._make_escape(0.8, l, d)\n\nnp.unique(l[np.argwhere(d == 1)], return_counts=True)\n\n(array([  8,  54, 101, 119, 144, 162, 176, 251, 283, 296, 304, 305, 346,\n        397, 416, 444, 476]),\n array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64))\n\n\nStokes drag\n\nclass models_phenom(models_phenom):\n    @staticmethod\n    def _stokes(D):\n        ''' Applies a Stokes-Einstein -like transformation to two\n        diffusion coefficients '''\n        D1 = D[0]; D2 = D[1]\n        return 1/((1/D1)+(1/D2))"
  },
  {
    "objectID": "models_phenom.html#time-evolution",
    "href": "models_phenom.html#time-evolution",
    "title": "models_phenom",
    "section": "Time evolution",
    "text": "Time evolution\nInput: - \\(N\\): (scalar) number of particles - \\(T\\): (scalar) length of the trajectory - \\(L\\): (scalar) length of the squared box acting as environment - \\(r\\): (scalar) size of the particles - \\(P_u\\): (scalar) unbinding probability - \\(P_b\\): (scalar) binding probability - \\(D\\)s: (2 x 3 array) \\((a,b,c)\\) parameters of the Pert distribution defining the diffusion coefficients for the two diffusive states. - \\(\\alpha\\)s: (2 x 3 array) \\((a,b,c)\\) parameters of the Pert distribution defining the anomalous exponent for the two diffusive states. - \\(\\gamma\\)s: (bool or float) if float, the \\(D_{dimer} = \\mathrm{mean}(D_1, D_2)/\\gamma\\)\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 500; L = 50; r = 1; T = 100\nPu = 0.1 # Unbinding probability\nPb = 1 # Binding probability\nDs = np.array([[2, 0], [0, 0]]) # Diffusion coefficients of two states\nalphas = np.array([[1, 0], [1, 0.2]]) # Anomalous exponents for two states\n\ntrajs, labels = models_phenom().dimerization(N = N,\n                                            L = L,\n                                            r = r,\n                                            T = T,\n                                            Pu = Pu, # Unbinding probability\n                                            Pb = Pb, # Binding probability\n                                            Ds = Ds, # Diffusion coefficients of two states\n                                            alphas = alphas, # Anomalous exponents for two states,\n                                            gamma = 3,\n                                            return_state_num = True,\n                                            stokes = True, epsilon_a=0.2\n                                            )\n\n\nfig, ax = plt.subplots(1,2, tight_layout = True)\nax[0].hist(labels[:,:,1].flatten(), bins = 100, density = 1)\nplt.setp(ax[0], title = r'Distribution of $D$ - both $\\mu=1$, $\\gamma_d = 0.8$', xlabel = r'$D$', ylabel = 'Frequency');\nax[1].hist(labels[:,:,0].flatten(), bins = 100, density = 1)\nplt.setp(ax[1], title = r'Distribution of $\\alpha$', xlabel = r'$\\alpha$', ylabel = 'Frequency');\n\n\n\n\n\nfig, ax = plt.subplots()\nax.hist(labels[:,:,0].flatten(), bins = 100)\nplt.setp(ax, title = r'Distribution of $\\alpha$', xlabel = r'$\\alpha$', ylabel = 'Frequency');\n\n\n\n\n\nfig, axs = plt.subplots(3, 4, figsize = (15, 7.5), tight_layout = True)\n\nfor idx, ax in enumerate(axs.transpose()):\n    part = np.random.randint(N)    \n    ax[0].set_title(f'Particle # {part}')\n    ax[0].plot(trajs[:, part, 0], trajs[:, part, 1], alpha = 0.5)\n    ax[0].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[1].plot(trajs[:, part, 0], 'o-', label = 'X', ms = 3, lw = 0.1)\n    ax[1].plot(trajs[:, part, 1], 'o-', label = 'Y', ms = 3, lw = 0.1)\n    ax[1].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[2].plot(labels[:, part, 0], 'o-', label = r'$\\alpha$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 1], 'o-', label = r'$D$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 2], 'o-', label = r'state', ms = 3, lw = 0.1, alpha = 0.3)\n\n\nplt.setp(axs[0, :], xlabel = 'X', ylabel = 'Y')\n\naxs[1, 0].legend()\nplt.setp(axs[1, 0], ylabel = 'Position')\nplt.setp(axs[1, :], xticklabels = '')\n\naxs[2, 0].legend()\nplt.setp(axs[2, 0], ylabel = 'Labels')\nplt.setp(axs[2, :], xlabel = 'Time');\n\n# plt.savefig('dimerization.svg')"
  },
  {
    "objectID": "models_phenom.html#auxiliary-functions-1",
    "href": "models_phenom.html#auxiliary-functions-1",
    "title": "models_phenom",
    "section": "Auxiliary functions",
    "text": "Auxiliary functions\n\nDistribute compartments\n\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nfig, ax = plt.subplots(figsize = (5,5))\n\nNc = 60; r = 10; L = 256;\ncomp_center = models_phenom._distribute_circular_compartments(Nc, r, L)\n\nfor c in comp_center:\n    circle = plt.Circle((c[0], c[1]), r)\n    ax.add_patch(circle)\nax.set_xlim(0,L)\nax.set_ylim(0,L)\n\n(0.0, 256.0)\n\n\n\n\n\n\n\nReflection inside circles\n\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\ncircle_radius = 2;\ncircle_center = [0,0]\nbeg = np.array([0.8, 0])+circle_center\nend = np.array([2.5, -0.8])+circle_center\n\nfinal_point, intersect = models_phenom._reflected_position(circle_center, circle_radius, beg, end)\n\nfig, ax = plt.subplots(figsize = (5, 5))\n\ncircle = plt.Circle(circle_center, circle_radius, facecolor = 'w', ec = 'C0', label = 'Compartment', zorder = -1)\nax.add_patch(circle)\nax.plot([beg[0],end[0]], [beg[1], end[1]], '-o', c = 'C1', label = 'Displacement segment')\nax.plot([circle_center[0], intersect[0]], [circle_center[1], intersect[1]], c = 'C2')\nax.plot([intersect[0], final_point[0]], [intersect[1], final_point[1]], '-o', c = 'C4', label = 'Resulting reflection')\nax.set_ylim(circle_center[1]-circle_radius*1.5, circle_center[1]+circle_radius*1.5)\nax.set_xlim(circle_center[0]-circle_radius*1.5, circle_center[0]+circle_radius*1.5)\nax.legend()\n\n<matplotlib.legend.Legend>"
  },
  {
    "objectID": "models_phenom.html#single-trajectory-generator-2",
    "href": "models_phenom.html#single-trajectory-generator-2",
    "title": "models_phenom",
    "section": "Single trajectory generator",
    "text": "Single trajectory generator\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 50;  L = 20\nNc = 15; r = 1; L = 20\nDs = [[1,0], [0.5,0.1]]\nr , L, Nc = (20, 256, 20)\n\ncomp_center = models_phenom._distribute_circular_compartments(Nc = Nc, r = r, L = L)\ntrajs, labels = models_phenom()._confinement_traj(trans = 0.1, Nc = Nc, r = r, L = L, T =200, comp_center=comp_center, Ds = [1, 1])\n\nfig, axs = plt.subplots(1,2, figsize = (10,5))\n\nax = axs[0]\nfor c in comp_center:\n    circle = plt.Circle((c[0], c[1]), r, facecolor = 'None', edgecolor = 'C0')\n    ax.add_patch(circle)    \n# ax.plot(trajs[:,0], trajs[:,1], c = 'C1', zorder = -2)   \nax.scatter(trajs[:,0], trajs[:,1], c = plt.cm.cividis(labels[:,-1]/2), zorder = -1, s = 2)   \n\nplt.setp(axs[0], xlim = (0,L), ylim = (0,L), xlabel = 'X', ylabel = 'Y')\n\naxs[1].plot(trajs[:,0], label = 'x');\naxs[1].plot(trajs[:,1], label = 'y');\naxs[1].legend()\nplt.setp(axs[1], xlabel = 'Position', ylabel = 'Time')\n\n[Text(0.5, 0, 'Position'), Text(0, 0.5, 'Time')]"
  },
  {
    "objectID": "models_phenom.html#dataset-generation-2",
    "href": "models_phenom.html#dataset-generation-2",
    "title": "models_phenom",
    "section": "Dataset generation",
    "text": "Dataset generation\nInput: - \\(N\\): (scalar) Number of trajectories in the dataset - Inputs of _confinement_traj\n\n\nmodels_phenom\n\n models_phenom ()\n\nConstructor of the class\n\nN = 500;  L = 20\nNc = 15; r = 1; L = 20\nDs = [[1,0], [0.5,0.1]]\nalphas = [[0.7, 0], [0.5,0.1]]\nr , L, Nc = (10, 256, 60)\ncomp_center = models_phenom._distribute_circular_compartments(Nc = Nc, r = r, L = L)\ntrajs, labels = models_phenom().confinement(N = N, L = L, comp_center = comp_center, trans = 0.2, Ds = Ds, \n                                            r = r, alphas = alphas, epsilon_a = [0.2])\n\n\nfig, axs = plt.subplots(3, 4, figsize = (15, 7.5), tight_layout = True)\n\n\nfor ax in axs.transpose():\n    \n    for c in comp_center:\n        circle = plt.Circle((c[0], c[1]), r, facecolor = 'None', edgecolor = 'C1', zorder = 10)\n        ax[0].add_patch(circle) \n    \n    part = np.random.randint(N)    \n    ax[0].set_title(f'Particle # {part}')\n    ax[0].plot(trajs[:, part, 0], trajs[:, part, 1], zorder = -2)\n    ax[0].scatter(trajs[:, part, 0], trajs[:, part, 1], c = labels[:, part, -1]/np.max(labels[:, part, -1]), zorder = -1, s = 4, cmap='cividis')   \n    ax[0].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[0].axvline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[1].plot(trajs[:, part, 0], '-', label = 'X', ms = 3, lw = 0.8)\n    ax[1].plot(trajs[:, part, 1], '-', label = 'Y', ms = 3, lw = 0.8)\n    ax[1].axhline(L, ls = '--', alpha = 0.3, c = 'k')\n    ax[1].axhline(0, ls = '--', alpha = 0.3, c = 'k')\n    \n    ax[2].plot(labels[:, part, 0], 'o-', label = r'$\\alpha$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 1], 'o-', label = r'$D$', ms = 3, lw = 0.1)\n    ax[2].plot(labels[:, part, 2], 'o-', label = r'state', ms = 3, lw = 0.1)\n\n\nplt.setp(axs[0, :], xlabel = 'X', ylabel = 'Y')\n\naxs[1, 0].legend()\nplt.setp(axs[1, 0], ylabel = 'Position')\nplt.setp(axs[1, :], xticklabels = '')\n\naxs[2, 0].legend()\nplt.setp(axs[2, 0], ylabel = 'Labels')\nplt.setp(axs[2, :], xlabel = 'Time');"
  },
  {
    "objectID": "models_theory.html",
    "href": "models_theory.html",
    "title": "models_theory",
    "section": "",
    "text": "Currently the library containts the following models: Function Dimensions Description - bm (1D) Brownian motion - fbm (1D/2D/3D) Fractional browian motion, simulated by the fbm python library - ctrw (1D/2D/3D) Continuous time random walks - lw (1D/2D/3D) Levy walks - attm (1D/2D/3D) Annealed transit time - sbm (1D/2D/3D) Scaled brownian motion\nInputs of generator functions: - T (int): lenght of the trajectory. Gets transformed to int if input is float. - alpha (float): anomalous exponent\nSome generator functions also have optional inputs, see each function for details.\nOutputs: - numpy.array of lenght d.T, where d is the dimension\nSome generator functions have optional outputs, see each function for details\n\nClass definition and general caller\n\n\nmodels_theory\n\n models_theory ()\n\nConstructor of the class\n\n\n\n1D theoretical diffusion models\n\n\nmodels_theory\n\n models_theory ()\n\nConstructor of the class\n\n\n\n2D theoretical diffusion models\n\n\nmodels_theory\n\n models_theory ()\n\nConstructor of the class\n\n\n\n3D theoretical diffusion models\n\n\nmodels_theory\n\n models_theory ()\n\nConstructor of the class\n\n\n\nNBDEV Export\n\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "utils_challenge.html",
    "href": "utils_challenge.html",
    "title": "utils_challenge",
    "section": "",
    "text": "Here we treat the labels extracted from models_phenom such as to have smoother ones. For instance, we will define a minimum segment length.\n\n\n\n\n label_filter (label, window_size=5, min_seg=3)\n\n\n\n\n\n\n majority_filter (seq, width)\n\n\nfig, axs = plt.subplots(10, 1, figsize = (20, 20))\nwindow_size = 5\n\nfor ax in axs:    \n    traj, labs = models_phenom()._multiple_state_traj(alphas = [0.7, 0.8], Ds = [0.01, 0.1])\n    filtered_d = label_filter(labs[:,1])\n    filtered_a = label_filter(labs[:,0])\n    \n    ax.plot(labs[:, 1], 'o', label = 'True label')\n    ax.plot(filtered_d, label = r'$D$')\n    ax.plot(filtered_a, label = r'$\\alpha$')\n    \naxs[0].set_title(f'Majority filter with window size = {window_size}')\naxs[0].legend()\nplt.setp(axs, xticklabels = []);\n\n\n\n\n\nfig, axs = plt.subplots(10, 1, figsize = (20, 20))\nfilt_size = 5\n\nM = [[0.8, 0.1, 0.1],[0.05, 0.9, 0.05], [0.05, 0.05, 0.9]]\nalphas = [0.7, 1, 1.2]\nDs = [0, 1, 2]\n\nfor ax in axs:    \n    traj, labs = models_phenom._multiple_state_traj(alphas = alphas, Ds = Ds, M = M)\n    filtered = label_filter(labs[:,1], window_size=filt_size)\n    \n    ax.plot(labs[:, 1], 'o', label = 'True label')\n    ax.plot(filtered, 'o-', ms = 2, label = f'median filter with window size = {filt_size}', lw = 2)\naxs[0].legend()\nplt.setp(axs, xticklabels = []);\n\n\n\n\n\n\n\n\nT = 1000\ntraj, labs = models_phenom().multi_state(N = 500, alphas = [0.7, 1], Ds = [0, 1], T = T)\n\nNameError: name 'label' is not defined\n\n\n\nres_t = np.array([])\nres_ft = np.array([])\nfor label in tqdm(labs.transpose(1,0,2)[:,:,0]):\n    \n    # raw labels\n    CP = np.argwhere(label[1:] != label[:-1]).flatten()\n    if CP[-1] != 199: CP = np.append(CP, T-1)\n    CP = np.append(0, CP)\n\n    res_t = np.append(res_t, CP[1:] - CP[:-1])\n    \n    \n    # filtered labels\n    filt = label_filter(label)\n    \n    CP_f = np.argwhere(filt[1:] != filt[:-1]).flatten()\n    if CP_f[-1] != 199: CP_f = np.append(CP_f, T-1)\n    CP_f = np.append(0, CP_f)\n\n    res_ft = np.append(res_ft, CP_f[1:] - CP_f[:-1])\n\n\n\n\n\nprint(f' True transition rate: {1/np.mean(res_t)}\\n',\n      f'Filtered transition rate: {1/np.mean(res_ft)}\\n',\n      f'True rate x 2/3: {1/np.mean(res_t)*(2/3)}')\n\n True transition rate: 0.10091711711711712\n Filtered transition rate: 0.06881721721721722\n True rate x 2/3: 0.06727807807807808\n\n\n\n1/0.10091711711711712\n\n9.909121748290453\n\n\n\n1/0.06881721721721722\n\n14.5312472726638\n\n\n\n\n\n\n\n\n\n stepwise_to_list (labels)\n\n\ntraj, labs = models_phenom._multiple_state_traj(alphas = [0.7, 1], Ds = [0, 1])\n\nfilt_alpha = label_filter(labs[:,0])\nfilt_D = label_filter(labs[:,1])\n\nCP, Ds, alphas = stepwise_to_list(np.vstack((filt_alpha, filt_D)).transpose())\n\nfig, ax = plt.subplots(figsize = (20, 3))\nax.plot(filt_alpha, zorder = -1)\nfor idx, cp in enumerate(CP): \n    ax.axvline(cp, c = 'k', ls = '--', alpha = 0.8, zorder = -1)\n    plt.scatter(cp, alphas[idx+1], c = 'C1', zorder = 2)"
  },
  {
    "objectID": "utils_challenge.html#changepoint-pairing",
    "href": "utils_challenge.html#changepoint-pairing",
    "title": "utils_challenge",
    "section": "Changepoint pairing",
    "text": "Changepoint pairing\nWe use an assignment algorithm to pair predicted and groundtruth changepoints. From there, we will calculate the various metrics of the challenge.\n\nchangepoint_assignment\n\n\n\nchangepoint_assignment\n\n changepoint_assignment (GT, preds)\n\nGiven a list of groundtruth and predicted changepoints, solves the assignment problem via the Munkres algorithm (aka Hungarian algorithm) and returns two arrays containing the index of the paired groundtruth and predicted changepoints, respectively.\n\nngts = 10; npreds = 6; T = 100\nGT = np.sort(np.random.choice(np.arange(1,T), ngts, replace = False))\npreds = np.sort(np.random.choice(np.arange(1,T)*0.5, npreds, replace = False))\nassig = changepoint_assignment(GT, preds)[0]\n\n\nGT[assig[0]]\n\narray([ 7, 13, 24, 30, 48, 55])\n\n\n\npreds[assig[1]]\n\narray([ 2.5,  5. ,  8. , 11.5, 30. , 34.5])\n\n\n\nchangepoint_assignment(GT, preds)[0]\n\n(array([4, 5, 6, 7, 8, 9], dtype=int64),\n array([5, 0, 1, 2, 4, 3], dtype=int64))\n\n\n\nchangepoint_alpha_beta\n\n\n\n\nchangepoint_alpha_beta\n\n changepoint_alpha_beta (GT, preds, treshold=10)\n\nCalculate the alpha and beta measure of paired changepoints. Inspired from Supplemantary Note 3 in https://www.nature.com/articles/nmeth.2808\n\nlabels = [r'Random Guess + $N_p>N_{gt}$',\n          r'Random Guess + $N_p<N_{gt}$',\n          r'GT + rand $\\in [-3, 3]$',\n          r'GT + rand $\\in [-1, 1]$']\n\nfig, ax = plt.subplots()\nalpha = 0.2\n\nT = 200; ngts = 15; \n\nfor case, (label, color) in enumerate(zip(labels, ['C0', 'C1', 'C2', 'C3'])):\n\n    alphas, betas = [], []\n    for _ in range(100):\n        \n        GT = np.sort(np.random.choice(np.arange(1,T), ngts, replace = False))\n        if case == 0:\n            npreds = np.random.randint(low = ngts, high = ngts*2)\n            preds = np.sort(np.random.choice(np.arange(1,T), npreds, replace = False)) \n        elif case == 1:\n            npreds = np.random.randint(low = 1, high = ngts)\n            preds = np.sort(np.random.choice(np.arange(1,T), npreds, replace = False))     \n        elif case == 2:\n            preds = GT + np.random.randint(-3, 3, ngts)\n        elif case == 3:\n            preds = GT + np.random.randint(-1, 1, ngts)\n            \n        alpha, beta = changepoint_alpha_beta(GT, preds)\n        \n        alphas.append(alpha)\n        betas.append(beta)\n     \n\n    \n    ax.scatter(alphas, betas, c = color, alpha = alpha)\n    ax.scatter(np.mean(alphas), np.mean(betas), c = color, label = label, s = 50, marker = 's', edgecolors = 'k')\nplt.setp(ax, xlabel = r'$\\alpha$', ylabel = r'$\\beta$')\nax.legend(loc = (0.91,0.4))\n\n<matplotlib.legend.Legend>\n\n\n\n\n\n\njaccard_index\n\n\n\n\njaccard_index\n\n jaccard_index (TP, FP, FN)\n\nGiven the true positive, false positive and false negative rates, calculates the Jaccard Index\n\nensemble_changepoint_error\n\n\n\n\nensemble_changepoint_error\n\n ensemble_changepoint_error (GT_ensemble, pred_ensemble, threshold=5)\n\nGiven an ensemble of groundtruth and predicted changepoints, iterates over each trajectory’s changepoints. For each, it solves the assignment problem between changepoints. Then, calculates the RMSE of the true positive pairs and the Jaccard index over the ensemble of changepoints (i.e. not the mean of them w.r.t. to the trajectories)\n\n\n\nchangepoint_error\n\n changepoint_error (GT, preds, threshold=5)\n\nGiven the groundtruth and predicted changepoints for a single trajectory, first solves the assignment problem between changepoints, then calculates the RMSE of the true positive pairs and the Jaccard index\n\nlabels = ['Random Guess + Incorrect number',\n          r'GT + rand $\\in [-3, 3]$',\n          r'GT + rand $\\in [-1, 1]$']\n\nfig, ax = plt.subplots()\nalpha = 0.2\n\nT = 200; ngts = 10; npreds = 8\n\nfor case, (label, color) in enumerate(zip(labels, ['C0', 'C1', 'C2'])):\n    \n    rmse, ji = [], []\n    GT, preds = [], []\n    for _ in range(100):\n\n        GT.append(np.sort(np.random.choice(np.arange(1,T), ngts, replace = False)))\n        if case == 0:\n            preds.append(np.sort(np.random.choice(np.arange(1,T), npreds, replace = False)))                  \n        elif case == 1:\n            preds.append(GT[-1] + np.random.randint(-3, 3, ngts))\n        elif case == 2:\n            preds.append(GT[-1] + np.random.randint(-1, 1, ngts))\n\n        assignment, _ = changepoint_assignment(GT[-1], preds[-1])\n        assignment = np.array(assignment)\n\n        RMSE, JI = changepoint_error(GT[-1], preds[-1], threshold = 5)     \n        \n        rmse.append(RMSE)\n        ji.append(JI)\n\n    rmse_e, ji_e = ensemble_changepoint_error(GT, preds, threshold = 5)\n    \n    ax.scatter(rmse, ji, c = color, alpha = alpha)\n    ax.scatter(rmse_e, ji_e, c = color, label = label, s = 50, marker = 's', edgecolors = 'k')\nplt.setp(ax, xlabel = 'TP RMSE', ylabel = 'Jaccard')\nax.legend(loc = (0.91,0.4))\n\n<matplotlib.legend.Legend>"
  },
  {
    "objectID": "utils_challenge.html#segments-pairing",
    "href": "utils_challenge.html#segments-pairing",
    "title": "utils_challenge",
    "section": "Segments pairing",
    "text": "Segments pairing\nHere we focus on pairing the segments arising from a list of changepoints. We will use this to latter compare the predicted physical properties for each segment\n\nsegment_distance\n\n\n\nsegment_distance\n\n segment_distance (seg1, seg2, epsilon=nan)\n\n\ncreate_binary_segment\n\n\n\n\ncreate_binary_segment\n\n create_binary_segment (CP, T)\n\nGiven a set of changepoints and the lenght of the trajectory, create segments which are equal to one if the segment takes place at that position and zero otherwise\n\nT= 50\nGT = np.sort(np.random.choice(np.arange(1,T), 10, replace = False))\nfor x in create_binary_segment(GT, T):\n    plt.plot(x, 'o')\n\n\n\n\n\njaccard_between_segments\n\n\n\n\njaccard_between_segments\n\n jaccard_between_segments (gt, pred)\n\nGiven two segments, calculates the Jaccard index between them by considering TP as correct labeling, FN as missed events and FP leftover predictions\n\nsegment_assignment\n\n\n\n\nsegment_assignment\n\n segment_assignment (GT, preds, T=None)\n\nGiven a list of groundtruth and predicted changepoints, generates a set of segments. Then constructs a cost matrix by calculting the Jaccard Index between segments. From this cost matrix, we solve the assignment problem via the Munkres algorithm (aka Hungarian algorithm) and returns two arrays containing the index of the groundtruth and predicted segments, respectively.\nIf T = None, then we consider that GT and preds may have different lenghts. In that case, the end of the segments is the the last CP of each set of CPs.\nEasy case\n\nT = 200; \nngts = 10; \nGT = np.sort(np.random.choice(np.arange(1,T), ngts, replace = False))\npreds = np.sort(GT + np.random.randint(-5, 5, 1) )\n\nseg_GT = create_binary_segment(GT, T)\nseg_preds = create_binary_segment(preds, T)   \n\n[row_ind, col_ind], cost_matrix = segment_assignment(GT, preds, T)\n\nfig, axs = plt.subplots(2, 5, figsize = (15, 6))\nfor r, c, ax in zip(row_ind, col_ind, axs.flatten()):\n    ax.set_title(f'1 - JI = {np.round(cost_matrix[r, c], 2)}')\n    ax.plot(seg_GT[r])\n    ax.plot(seg_preds[c])\n\n\n\n\nDifferent size pred / true\n\nT1 = 200; T2 = 100\nngts = 10; \nGT = np.sort(np.random.choice(np.arange(1,T1), ngts, replace = False))\npreds = np.sort(np.random.choice(np.arange(1,T2), 5, replace = False))\n\nseg_GT = create_binary_segment(GT, T1)\nseg_preds = create_binary_segment(preds, T2)   \n\n[row_ind, col_ind], cost_matrix = segment_assignment(GT, preds)\n\nfig, axs = plt.subplots(2, 5, figsize = (15, 6))\nfor r, c, ax in zip(row_ind, col_ind, axs.flatten()):\n    ax.set_title(f'1 - JI = {np.round(cost_matrix[r, c], 2)}')\n    ax.plot(seg_GT[r])\n    ax.plot(seg_preds[c])\n\n\n\n\nDifficult case\n\nT = 200;\nngts = 5; npreds = 6;\nGT = np.sort(np.random.choice(np.arange(1,T), ngts, replace = False))\npreds = np.sort(np.random.choice(np.arange(1,T), npreds, replace = False))  \n\n# fig, ax = plt.subplots()\n# plt.plot(GT, np.ones(ngts), 'o')\n# plt.plot(preds, np.ones(npreds)*0.9, 'o')\n\nseg_GT = create_binary_segment(GT, T)\nseg_preds = create_binary_segment(preds, T)\n\n[row_ind, col_ind], cost_matrix = segment_assignment(GT, preds, T)\n\nfig, axs = plt.subplots(2, 5, figsize = (15, 6))\nfor r, c, ax in zip(row_ind, col_ind, axs.flatten()):\n    ax.set_title(f'1 - JI = {np.round(cost_matrix[r, c], 2)}')\n    ax.plot(seg_GT[r], label = 'GT')\n    ax.plot(seg_preds[c], label = 'Assigned pred', alpha = 0.6)\naxs[0,0].legend()\n\n<matplotlib.legend.Legend>"
  },
  {
    "objectID": "utils_challenge.html#segment-properties-comparison",
    "href": "utils_challenge.html#segment-properties-comparison",
    "title": "utils_challenge",
    "section": "Segment properties comparison",
    "text": "Segment properties comparison\n\nMetrics of segment properties\n\n\n\nmetric_diffusive_state\n\n metric_diffusive_state (gt=None, pred=None, max_error=False)\n\n\n\n\nmetric_diffusion_coefficient\n\n metric_diffusion_coefficient (gt=None, pred=None, threshold_min=1e-12,\n                               max_error=False)\n\n\n\n\nmetric_anomalous_exponent\n\n metric_anomalous_exponent (gt=None, pred=None, max_error=False)\n\n\nx = np.random.rand(100)\ny = np.random.rand(100)\n\n\nmean_squared_log_error([1e6],[1e-12])\n\n190.86835960820298\n\n\n\nmetric_diffusion_coefficient(x+2,y+2, threshold_min=-2)\n\n0.01379558958923705\n\n\n\ncheck_no_changepoints\n\n\n\n\ncheck_no_changepoints\n\n check_no_changepoints (GT_cp, GT_alpha, GT_D, GT_s, preds_cp,\n                        preds_alpha, preds_D, preds_s, T=None)\n\nGiven predicionts over changepoints and variables, checks if in both GT and preds there is an absence of changepoint. If so, takes that into account to pair variables.\n\nsegment_property_errors\n\n\n\n\nsegment_property_errors\n\n segment_property_errors (GT_cp, GT_alpha, GT_D, GT_s, preds_cp,\n                          preds_alpha, preds_D, preds_s,\n                          return_pairs=False, T=None)\n\n\nT = 200; \nngts = 10; \nerrors_alpha = np.linspace(0, 1, ngts)\nerrors_d = np.linspace(0, 10, ngts)\n\nmetric_a, metric_d = [], []\nfor error_a, error_d in zip(errors_alpha, errors_d):\n    la, ld = [], []\n    for _ in range(100):\n\n        GT_cp = np.sort(np.random.choice(np.arange(1,T-1), ngts, replace = False))\n        preds_cp = np.sort(np.random.choice(np.arange(1,T-1), ngts, replace = False)) \n\n        GT_alpha = np.random.rand(GT_cp.shape[0]+1)\n        preds_alpha = GT_alpha + np.random.randn(preds_cp.shape[0]+1)*error_a\n\n        GT_D = np.abs(np.random.randn(GT_cp.shape[0]+1)*10)\n        preds_D = GT_D + np.abs(np.random.randn(preds_cp.shape[0]+1))*error_d\n        \n        GT_s = np.random.randint(0, 5, GT_cp.shape[0]+1)\n        pred_s = np.random.randint(0, 5, preds_cp.shape[0]+1)\n\n        m_a, m_d, m_s = segment_property_errors(GT_cp, GT_alpha, GT_D, GT_s, preds_cp, preds_alpha, preds_D, preds_s, T = T)\n        \n        la.append(m_a); ld.append(m_d)\n    \n    metric_a.append(np.mean(la))\n    metric_d.append(np.mean(ld))\n\n\nfig, ax = plt.subplots(1, 2, figsize = (10, 5))\n\nax[0].plot(np.arange(ngts), errors_alpha, c = 'C0', ls = '--')\nax[0].plot(np.arange(ngts), metric_a, c = 'C0')\nax[0].set_title(r'Error in $\\alpha$')\n\n# ax[1].plot(np.arange(ngts), errors_d, c = 'C1', ls = '--')\nax[1].plot(np.arange(ngts), metric_d, c = 'C1')\nax[1].set_title(r'Error in $D$')\n\nText(0.5, 1.0, 'Error in $D$')"
  },
  {
    "objectID": "utils_challenge.html#ensemble-metrics",
    "href": "utils_challenge.html#ensemble-metrics",
    "title": "utils_challenge",
    "section": "Ensemble metrics",
    "text": "Ensemble metrics\n\nextract_ensemble\n\n\n\nextract_ensemble\n\n extract_ensemble (state_label, dic)\n\nGiven an array of the diffusive state and a dictionary with the diffusion information, returns a summary of the ensemble properties for the current dataset.\nArgs: :state_label (array): Array containing the diffusive state of the particles in the dataset. For multi-state and dimerization, this must be the number associated to the state (for dimerization, 0 is free, 1 is dimerized). For the rest, we follow the numeration of models_phenom().lab_state. :dic (dictionary): Dictionary containing the information of the input dataset. Returns: :ensemble (array): Matrix containing the ensemble information of the input dataset. It has the following shape: |mu_alpha1 mu_alpha2 … | |sigma_alpha1 sigma_alpha2 … | |mu_D1 mu_D1 … | |sigma_D1 sigma_D2 … | |counts_state1 counts_state2 … |\n\n\nGenerating multimodal from mean and variance\n\n\n\nmultimode_dist\n\n multimode_dist (params, weights, bound, x, normalized=False)\n\n\n\nDistance between distributions\n\n\n\ndistribution_distance\n\n distribution_distance (p, q)\n\nhttps://stackoverflow.com/questions/44549369/kullback-leibler-divergence-from-gaussian-pm-pv-to-gaussian-qm-qv\n\nimport scipy\nfrom scipy import stats\nfrom scipy.stats import beta as beta_func\nimport numpy as np\nimport random\n\n\nminimum = 1\nmode = 2\nmaximum = 3\n\nd = (minimum + 4*mode + maximum)/6\nalpha = 6*((d - minimum)/(maximum - minimum))\nbeta = 6*((maximum - d)/(maximum - minimum))\n\nlocation = minimum\nscale = maximum - minimum\n\nx = np.arange(-1, 5, 0.001)\n\n\npert = beta_func.pdf(x, alpha, beta, location, scale)\n\n\nmeans = np.linspace(0, 2, 30)\nnormalize = False\nfig = plt.figure(figsize=(20, 5))\ngs = fig.add_gridspec(2, 10)\n\n# True distribution\nx = np.arange(0, 3, 0.01)\nparams = [[1.7,0.01]]\nweights = [1]\ntrue = multimode_dist(params, weights, bound = [0, 3], x = x, normalized = normalize)\n\n\n\nKL = []\nfor idx, mean in enumerate(means):\n    params = [[mean, 0.01]]\n    weights = [1]\n    pred = multimode_dist(params, weights, bound = [0, 3], x = x, normalized = normalize)  \n    KL.append(distribution_distance(true, pred))  \n    \n    if idx % 3 == 0:\n        \n        ax = fig.add_subplot(gs[0, int(idx/3)])\n        ax.plot(x, true, label = 'True')\n        ax.plot(x, pred, label = 'Predicted')        \n        plt.setp(ax, yticks = []);\n        \n      \n    if idx == 0:\n        ax.legend()\n    \nax_kl = fig.add_subplot(gs[1, :])\nax_kl.plot(KL, '-o')\nplt.setp(ax_kl, ylabel = 'MAE')\nax_kl.grid()\n\n\n\n\n\n\nCalculate ensemble metric\nInputs are matrices of form:\n\\(\\mu_\\alpha^1\\); \\(\\mu_\\alpha^2\\) ; …\n\\(\\sigma_\\alpha^1\\); \\(\\sigma_\\alpha^2\\) ; …\n\\(\\mu_D^1\\) ; \\(\\mu_D^2\\) ; …\n\\(\\sigma_D^1\\) ; \\(\\sigma_D^2\\) ; …\n\\(N_1\\), \\(N_2\\), …\n\n\n\nerror_Ensemble_dataset\n\n error_Ensemble_dataset (true_data, pred_data, return_distributions=False)"
  },
  {
    "objectID": "utils_challenge.html#reading-participants-predictions",
    "href": "utils_challenge.html#reading-participants-predictions",
    "title": "utils_challenge",
    "section": "Reading participants predictions",
    "text": "Reading participants predictions\nThe participants will have to output predictions in a .txt file were each line corresponds to the predictions of a trajectory. The latter have to be ordered as:\n0, d\\(_0\\), a\\(_0\\), s\\(_0\\), t\\(_1\\), d\\(_1\\), a\\(_1\\), s\\(_1\\), t\\(_2\\), d\\(_2\\), a\\(_2\\), s\\(_2\\), …. t\\(_n\\), d\\(_n\\), a\\(_n\\), s\\(_n\\)\nwhere the first number corresponds to the trajectory index, then d\\(_i\\), a\\(_i\\), s\\(_i\\) correspond to the diffusion coefficient, anomalous exponent and diffusive state of the \\(i\\)-th segment. For the latter, we have the following code: - 0: immobile - 1: confined - 2: brownian - 3: anomalous\nLast, t\\(_j\\) corresponds to the \\(j\\)-th changepoints. Each prediction must contain \\(C\\) changepoints and \\(C+1\\) segments property values. If this is not fulfilled, the whole trajectory is considered as mispredicted.\nThe .txt file will be first inspected. The data will then be collected into a dataframe\n\ncheck_prediction_length\n\n\n\ncheck_prediction_length\n\n check_prediction_length (pred)\n\nGiven a trajectory segments prediction, checks whether it has C changepoints and C+1 segments properties values. As it must also contain the index of the trajectory, this is summarized by being multiple of 4. In some cases, the user needs to also predict the final point of the trajectory. In this case, we will have a residu of 1\n\nseparate_prediction_values\n\n\n\n\nseparate_prediction_values\n\n separate_prediction_values (pred)\n\nGiven a trajectory segments prediction, extracts the predictions for each segment property as well as the changepoint values\n\nload_file_to_df\n\n\n\n\nload_file_to_df\n\n load_file_to_df (path_file, columns=['traj_idx', 'Ds', 'alphas',\n                  'states', 'changepoints'])\n\nGiven the path of a .txt file, extract the segmentation predictions based on the rules of the ANDI Challenge 2022\nSaving fake data for test\n\nfile_gt, file_p = [], []\nT = 200; ngts = 10;\nfor traj in range(100):\n    GT_cp = np.sort(np.random.choice(np.arange(1,T), ngts, replace = False))\n    preds_cp = np.sort(np.random.choice(np.arange(1,T+50), ngts, replace = False)) \n\n    GT_alpha = np.random.rand(GT_cp.shape[0]+1)\n    preds_alpha = GT_alpha# + 0.1 #np.random.randn(preds_cp.shape[0]+1)*0.1\n\n    GT_D = np.abs(np.random.randn(GT_cp.shape[0]+1)*10)\n    preds_D = GT_D + 1.5 #np.abs(np.random.randn(preds_cp.shape[0]+1))*1.6\n    \n    GT_state = np.random.randint(0, high = 5, size = GT_cp.shape[0]+1)\n    preds_state = np.random.randint(0, high = 5, size = preds_cp.shape[0]+1)\n    \n    list_gt, list_p = [traj, GT_D[0], GT_alpha[0], GT_state[0]], [traj, preds_D[0], preds_alpha[0], preds_state[0]]\n    for gtc, gta, gtd, gts, pc, pa, pd, ps in zip(GT_cp, GT_alpha[1:], GT_D[1:], GT_state[1:], preds_cp, preds_alpha[1:], preds_D[1:], preds_state[1:]):\n        list_gt += [gtc, gtd, gta, gts]\n        list_p += [pc, pd, pa, ps]\n        \n    file_gt.append(list_gt)\n    if traj != 6:\n        file_p.append(list_p)\n        \npred_path, true_path = 'pred_test.txt', 'true_test.txt'\nnp.savetxt(true_path, file_gt, delimiter=',')\nnp.savetxt(pred_path, file_p, delimiter=',')\n\nRecovering the data\n\npred_path, true_path = 'pred_test.txt', 'true_test.txt'\n\ndf_pred = load_file_to_df(pred_path)\ndf_true = load_file_to_df(true_path)\n\n\nerror_SingleTraj_dataset\n\n\n\n\nerror_SingleTraj_dataset\n\n error_SingleTraj_dataset (df_pred, df_true, threshold_error_alpha=2,\n                           max_val_alpha=2, min_val_alpha=0,\n                           threshold_error_D=100000.0,\n                           max_val_D=1000000.0, min_val_D=1e-06,\n                           threshold_error_s=-1, threshold_cp=10,\n                           prints=True, disable_tqdm=False)\n\nGiven two dataframes, corresponding to the predictions and true labels of a set of trajectories from the ANDI challenge 2022, calculates the corresponding metrics Columns must be for both (no order needed): traj_idx | alphas | Ds | changepoints | states df_true must also contain a column ‘T’\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf_pred\n\n\n\n\n\ndf_true\n\n\n\n\n\nthreshold_error_alpha\nint\n2\n\n\n\nmax_val_alpha\nint\n2\n\n\n\nmin_val_alpha\nint\n0\n\n\n\nthreshold_error_D\nfloat\n100000.0\n\n\n\nmax_val_D\nfloat\n1000000.0\n\n\n\nmin_val_D\nfloat\n1e-06\nthis is in linear scale\n\n\nthreshold_error_s\nint\n-1\nthis will transform nan into non-existing state\n\n\nthreshold_cp\nint\n10\n\n\n\nprints\nbool\nTrue\n\n\n\ndisable_tqdm\nbool\nFalse\n\n\n\n\n\nTest\nTwo datasets with same number of trajs\n\ntrajs, labels = models_phenom().immobile_traps(T = 200, N = 250, alphas=0.5, Ds = 1, L = 20, Nt = 100, Pb = 1, Pu = 0.5)\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_trues = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\ntrajs, labels = models_phenom().immobile_traps(T = 200, N = 250, alphas=[0.5, 0.1], Ds = 1, L = 20, Nt = 100, Pb = 1, Pu = 0.5)\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_preds = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\n\n\n\n\n\n\n\nerror_SingleTraj_dataset(df_preds, df_trues, prints = True)\n\n\n\n\nSummary of metrics assesments:\n\nChangepoint Metrics \nRMSE: 3.977 \nJaccard Index: 0.436 \n\nDiffusion property metrics \nMetric anomalous exponent: 0.3196485708934536 \nMetric diffusion coefficient: 0.233730617081089 \nMetric diffusive state: 0.5135203436947182\n\n\n(3.9773268837631606,\n 0.43570617804443,\n 0.3196485708934536,\n 0.233730617081089,\n 0.5135203436947182)\n\n\nTwo datasets with different number of trajectories\n\ntrajs, labels = models_phenom().immobile_traps(T = 200, N = 350, alphas=[0.5,0.01], Ds = [1., 0.1], L = 20, Nt = 100, Pb = 1, Pu = 0.5)\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_trues = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\ntrajs, labels = models_phenom().immobile_traps(T = 200, N = 250, alphas=[0.5, 0.1], Ds = 1, L = 20, Nt = 100, Pb = 1, Pu = 0.5)\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_preds = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\n\n\n\n\n\n\n\nerror_SingleTraj_dataset(df_preds, df_trues, prints = True)\n\n\n\n\nSummary of metrics assesments:\n\n100 missing trajectory/ies. \n\nChangepoint Metrics \nRMSE: 4.051 \nJaccard Index: 0.441 \n\nDiffusion property metrics \nMetric anomalous exponent: 0.35483874584715985 \nMetric diffusion coefficient: 3.1690909054732668 \nMetric diffusive state: 0.4913685263947961\n\n\n(4.050708208970335,\n 0.4407643312101911,\n 0.35483874584715985,\n 3.1690909054732668,\n 0.4913685263947961)\n\n\n\ntrajs, labels = models_phenom().immobile_traps(T = 200, N = 5, alphas=[0.5,0.01], Ds = [1., 0.1], L = 20, Nt = 100, Pb = 1, Pu = 0.5)\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_preds  = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\ntrajs, labels = models_phenom().multi_state(T = 200, N = 7, L = 20, M = np.array([[0.9,0.1],[0.9,0.1]]))\n\ntrajs = trajs.transpose((1, 0, 2)).copy()\nlabels = labels.transpose(1, 0, 2)\n\ndf_in, df_trues  = data_to_df(trajs, labels, label_values=[0.5, 1], diff_states=[3, 2])\n\n\n\n\n\n\n\n\nerror_SingleTraj_dataset(df_preds, df_trues, prints = True);\n\n\n\n\nSummary of metrics assesments:\n\n2 missing trajectory/ies. \n\nChangepoint Metrics \nRMSE: 2.903 \nJaccard Index: 0.188 \n\nDiffusion property metrics \nMetric anomalous exponent: 0.8269399281523714 \nMetric diffusion coefficient: 8.262443034681892 \nMetric diffusive state: 0.41379310344827586"
  },
  {
    "objectID": "utils_trajectories.html",
    "href": "utils_trajectories.html",
    "title": "utils_trajectories",
    "section": "",
    "text": "Trigonometry functions\nNeeded for the correct calculation of confined diffusion in circular compartments.\n\n\ntrigo\n\n trigo ()\n\nExtracted from https://stackoverflow.com/questions/30844482/what-is-most-efficient-way-to-find-the-intersection-of-a-line-and-a-circle-in-py\n\n\n\nAdding field of view (FOV)\n\n\nfind_nan_segments\n\n find_nan_segments (a, cutoff_length)\n\nExtract all segments of nans bigger than the set cutoff_length. If no segments are found, returns None. For each segments, returns the begining and end index of it.\nOutput: array of size (number of segments) x 2.\n\n\n\nsegs_inside_fov\n\n segs_inside_fov (traj, fov_origin, fov_length, cutoff_length)\n\nGiven a trajectory, finds the segments inside the field of view (FOV).\nArgs: :traj (array): set of trajectories of size N x T (N: number trajectories, T: length) :fov_origin (tuple): bottom right point of the square defining the FOV :fov_length (scalar): size of the box defining the FOV :cutoff_length (scalar): minimum length of a trajectory inside the FOV to be considered in the output dataset Return :segs_fov: set of segments inside the FOV\n\n\n\ninside_fov_dataset\n\n inside_fov_dataset (trajs, labels, fov_origin, fov_length,\n                     cutoff_length=10, func_labels=None,\n                     return_frames=False)\n\nGiven a dataset of trajectories with labels and a FOV parameters, returns a list of trajectories with the corresponding labels inside the FOV Args: :trajs (array): set of trajectories with shape T x N x 2. :labels (array): set of labels with shape T x N x 2. :fov_origin (tuple): bottom left point of the square defining the FOV. :fov_length (scalar): size of the box defining the FOV. :cutoff_length (scalar): minimum length of a trajectory inside the FOV to be considered in the output dataset. :func_labels (func): optinal function to be applied to the labels to take advantage of the loop Return: :trajs_fov (list): list 2D arrays containing the trajectories inside the field of view. :labels_fov (list): corresponding labels of the trajectories.\n\n\nTest\n\nL = 200; T = 100\nNs = [20,10,10]\nalphas = [1,1.5]\nD = 1   \n\ntrajs, labels = models_phenom().multi_state(N = 500, L = L, T = 50)\n\n\nfov_origin = [50,50]; fov_length = L*0.1\ntrajs_fov, labels_fov = inside_fov_dataset(trajs, labels, fov_origin, fov_length)\n\n\n\n\nPlotting trajectories\n\n\nplot_trajs\n\n plot_trajs (trajs, L, N, num_to_plot=3, labels=None, plot_labels=False,\n             traps_positions=None, comp_center=None, r_cercle=None)\n\n\nT = 500; N = 50; L = 1.2*128; D = 0.1\n\ntrajs_model1, labels = models_phenom().single_state(N = N, \n                                            L = L,\n                                            T = T,\n                                            Ds = D,\n                                            alphas = 0.5\n                                            )\n\nplot_trajs(trajs_model1, L, N)\n\n\n\n\n\n\n\nnbdev\n\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "utils_videos.html",
    "href": "utils_videos.html",
    "title": "utils_videos",
    "section": "",
    "text": "transform_to_video\n\n\ntransform_to_video\n\n transform_to_video (trajectory_data, particle_props={}, optics_props={},\n                     background_props={}, get_vip_particles=[],\n                     with_masks=False, save_video=False, path='')\n\nGenerates a video from a trajectory data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrajectory_data\nnp.ndarray\n\nGenerated through models_phenom. Array of shape (T, N, 2) containing the trajectories.\n\n\nparticle_props\ndict\n{}\nDictionary of properties for the particles.\n\n\noptics_props\ndict\n{}\nDictionary of properties for the optics.\n\n\nbackground_props\ndict\n{}\nDictionary of properties for the background.\n\n\nget_vip_particles\nlist\n[]\n\n\n\nwith_masks\nbool\nFalse\n\n\n\nsave_video\nbool\nFalse\n\n\n\npath\nstr\n\n\n\n\n\n\n\nTesting PSF size\n\nT = 10 # number of time steps (frames)\nN = 50 # number of particles (trajectories)\nL = 1* 128 # length of the box (pixels) -> exteneding fov by 1.5 times\nD = 0.1 # diffusion coefficient (pixels^2/frame)\ntrajs_test, labels = models_phenom().single_state(N=N, L=L, T=T, Ds=D, alphas=0.5)\n\n\nvideo = transform_to_video(\n    trajs_test,\n    optics_props={\"NA\": 1.46,\n                  \"wavelength\":500e-9},\n    particle_props={\"particle_intensity\": [100, 0], \"z\":0},\n    get_vip_particles= [1,2,3],\n    background_props={\"background_mean\":0, \"background_std\":0},\n    save_video=True, path = 'video_test.tiff', with_masks = False\n)\n\n\ndetections = np.array(video[1].get_property(\"position\", get_one=False))\nplt.figure(figsize=(7,7))\nplt.imshow(video[1], cmap=\"gray\")\nplt.scatter(detections[:,1], detections[:,0], marker='o', s=500, facecolors=\"none\", edgecolors=\"orange\")\n[plt.text(y+2, x, str(i), color=\"orange\") for i, (x, y) in enumerate(detections)]\nplt.show()\n\n\n\n\n\ncrop = croppedimage(video[0], list(reversed(detections[46])), window=8)\n\n\nplt.imshow(crop, cmap=\"gray\")\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar>\n\n\n\n\n\n\n\nTesting generation\n\nfrom andi_datasets.models_phenom import models_phenom\n\n\ntrajs_test, _ = models_phenom().single_state(N = 50, T = 100, L = 128, Ds = 1)\nvideo, masks = transform_to_video(trajs_test,\n                                  with_masks=True,\n                                  get_vip_particles=np.arange(55).tolist(),\n                                  particle_props = {\"z\": lambda: 0 + np.random.rand() * 1},\n                                  background_props = {\"background_mean\": 0,      # Mean background intensity\n                                                      \"background_std\": 0}, \n                                 optics_props = {'origin': [0,0,20,20]})\n\n\nplay_video(video)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\nimg2 = ax1.imshow(video[1], cmap=\"gray\")\nax1.set_title(\"Frame 0\")\nax2.imshow(masks[1], cmap=\"gray\")\nax2.set_title(\"Mask 0\")\n\nText(0.5, 1.0, 'Mask 0')\n\n\n\n\n\n\nplt.figure(figsize=(5, 5))\nplt.imshow(video[0], cmap=\"gray\", zorder = -1)\nfor traj in np.moveaxis(trajs_test, 0, 1):\n    plt.plot(traj[:,1], traj[:,0], alpha=0.2)\nplt.xlim(0,L); plt.ylim(0,L)\nplt.show()\n\n\n\n\n\n\n\nNbdev\n\nimport nbdev; nbdev.nbdev_export()"
  }
]