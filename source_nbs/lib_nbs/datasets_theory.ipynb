{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6adb1f2",
   "metadata": {},
   "source": [
    "# `datasets_theory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b345fa-e26f-4cfc-b685-1f4a012c0da4",
   "metadata": {},
   "source": [
    "Main class for generating datasets of theoretical trajectories. For details on this class, please check [this tutorial](../tutorials/challenge_one_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a775b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import os\n",
    "import inspect\n",
    "import h5py\n",
    "from tqdm.auto import trange\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from andi_datasets.utils_trajectories import normalize\n",
    "from andi_datasets.models_theory import models_theory as models_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf99d70-b764-43f7-8cfb-6d1d1c551e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class datasets_theory():\n",
    "     \n",
    "    def __init__(self):        \n",
    "        '''\n",
    "        This class generates, saves and loads datasets of theoretical trajectories simulated \n",
    "        from various diffusion models (available at andi_datasets.models_theory). \n",
    "        '''\n",
    "        self._dimension = 1\n",
    "        self._get_models()\n",
    "        \n",
    "    def _get_models(self):        \n",
    "        '''Loading subclass of models'''\n",
    "        if self._dimension == 1:\n",
    "            self._models = models_theory._oneD()\n",
    "        elif self._dimension == 2:\n",
    "            self._models = models_theory._twoD()\n",
    "        elif self._dimension == 3:\n",
    "            self._models = models_theory._threeD()\n",
    "        else:\n",
    "            raise ValueError('Our current understanding of the physical world is three dimensional and so are the diffusion models available in this class')\n",
    "                \n",
    "        available_models = inspect.getmembers(self._models, inspect.ismethod)      \n",
    "        self.avail_models_name = [x[0] for x in available_models]\n",
    "        self.avail_models_func = [x[1] for x in available_models]\n",
    "    \n",
    "    def create_dataset(self, T, N_models, exponents, models,\n",
    "                       dimension = 1,\n",
    "                       save_trajectories = False, load_trajectories = False, \n",
    "                       path = 'datasets/',\n",
    "                       N_save = 1000, t_save = 1000):        \n",
    "        ''' \n",
    "        Creates a dataset of trajectories via the theoretical models defined in `.models_theory`. Check our tutorials for use cases of this function.\n",
    "        \n",
    "        Inputs\n",
    "        --------\n",
    "            :T (int):\n",
    "                - length of the trajectories.   \n",
    "            :N_models (int, numpy.array):\n",
    "                - if int, number of trajectories per class (i.e. exponent and model) in the dataset.\n",
    "                - if numpy.array, number of trajectories per classes: size (number of models)x(number of classes)    \n",
    "            :exponents (float, array):\n",
    "                - anomalous exponents to include in the dataset. Allows for two digit precision.\n",
    "            :models (bool, int, list):\n",
    "                - labels of the models to include in the dataset. Correspodance between models and labels\n",
    "                  is given by self.label_correspodance, defined at init.\n",
    "                  If int/list, choose the given models. If False, choose all of them.\n",
    "            :dimensions (int):\n",
    "                - Dimensions of the generated trajectories. Three possible values: 1, 2 and 3.\n",
    "            :save_trajectories (bool):\n",
    "                - - if True, the module saves a .h5 file for each model considered, with N_save trajectories \n",
    "                  and T = T_save.\n",
    "            :load_trajectories (bool):\n",
    "                - if True, the module loads the trajectories of an .h5 file.\n",
    "            :path (str):\n",
    "                - path to the folder where to save/load the trajectories dataset.\n",
    "            :N_save (int):\n",
    "                - Number of trajectories to save for each exponents/model. Advise: save at the beggining\n",
    "                  a big dataset (t_save ~ 1e3 and N_save ~ 1e4) which allows you to load any other combiantion\n",
    "                  of T and N_models.\n",
    "            :t_save (int):\n",
    "                - Length of the trajectories to be saved. See comments on N_save.                \n",
    "        Outputs\n",
    "        ----\n",
    "            :data_models (numpy.array):\n",
    "                - Dataset of trajectories of lenght Nx(T+2), with the following structure:\n",
    "                    o First column: model label \n",
    "                    o Second column: value of the anomalous exponent\n",
    "                    o 2:T columns: trajectories\n",
    "        '''\n",
    "                    \n",
    "        '''Managing probable errors in inputs'''\n",
    "        if T < 2:\n",
    "            raise ValueError('The time of the trajectories has to be bigger than 1.')       \n",
    "        if isinstance(exponents, int) or isinstance(exponents, float):\n",
    "            exponents = [exponents]\n",
    "        \n",
    "        '''Managing folders of the datasets'''       \n",
    "        if save_trajectories or load_trajectories:                \n",
    "            if load_trajectories:\n",
    "                save_trajectories = False            \n",
    "            if not os.path.exists(path) and load_trajectories:\n",
    "                raise FileNotFoundError('The directory from where you want to load the dataset does not exist')                \n",
    "            if not os.path.exists(path) and save_trajectories:\n",
    "                os.makedirs(path)  \n",
    "                \n",
    "        '''Establish dimensions and corresponding models'''\n",
    "        self._dimension = dimension\n",
    "        self._get_models()\n",
    "                \n",
    "        '''Managing models to load'''       \n",
    "        # Load from a list of models\n",
    "        if isinstance(models, list): \n",
    "            self._models_name = [self.avail_models_name[idx] for idx in models]     \n",
    "            self._models_func = [self.avail_models_func[idx] for idx in models]\n",
    "        # Load from a single model\n",
    "        elif isinstance(models, int) and not isinstance(models, bool):\n",
    "            self._models_name = [self.avail_models_name[models]]\n",
    "            self._models_func = [self.avail_models_func[models]]\n",
    "        # Load all available models\n",
    "        else: \n",
    "            self._models_name =  self.avail_models_name\n",
    "            self._models_func =  self.avail_models_func\n",
    "            \n",
    "        '''Managing number of trajectory per class:\n",
    "            - Defines array num_class as a function of N'''                            \n",
    "        if isinstance(N_models, int): \n",
    "            n_per_class = N_models*np.ones((len(self._models_name), len(exponents)))\n",
    "            \n",
    "        elif type(N_models).__module__ == np.__name__: \n",
    "            if len(self._models_name) != N_models.shape[0] or len(exponents) != N_models.shape[1]:\n",
    "                raise ValueError('Mismatch between the dimensions of N and the number of different classes.'+\n",
    "                                 f'N must be either an int (balanced classes) or an array of length {len(models)}x'\n",
    "                                 f'{len(exponents)} (inbalaced classes).') \n",
    "            n_per_class = N_models\n",
    "        else:\n",
    "            raise TypeError('Type of variable N not recognized.')\n",
    "                    \n",
    "        '''Defining default values for saved datasets''' \n",
    "        N_save = np.ones_like(n_per_class)*N_save\n",
    "        # If the number of class of a given class is bigger than N_save, we\n",
    "        # change the value of N_save for that particular class.\n",
    "        N_save = np.max([N_save, n_per_class], axis = 0)      \n",
    "                \n",
    "        ''' Loading/Saving/Creating datasets'''\n",
    "        if load_trajectories:\n",
    "            data_models = self._load_trajectories(T = T,\n",
    "                                                 exponents = exponents,\n",
    "                                                 models_name = self._models_name,\n",
    "                                                 dimension = self._dimension,\n",
    "                                                 n_per_class = n_per_class,\n",
    "                                                 path = path,\n",
    "                                                 N_save = N_save,\n",
    "                                                 t_save = t_save)\n",
    "        elif save_trajectories:\n",
    "            self._save_trajectories(exponents = exponents,\n",
    "                                   dimension = self._dimension,\n",
    "                                   models_name = self._models_name,\n",
    "                                   models_func = self._models_func,\n",
    "                                   path = path, \n",
    "                                   n_per_class = n_per_class,\n",
    "                                   N_save = N_save,\n",
    "                                   t_save = t_save)\n",
    "            \n",
    "            data_models = self._load_trajectories(T = T,\n",
    "                                                 exponents = exponents,\n",
    "                                                 dimension = self._dimension,\n",
    "                                                 models_name = self._models_name,                                                 \n",
    "                                                 n_per_class = n_per_class,\n",
    "                                                 path = path,\n",
    "                                                 N_save = N_save,\n",
    "                                                 t_save = t_save)\n",
    "            \n",
    "        else:           \n",
    "            data_models = self._create_trajectories(T = T,                                                   \n",
    "                                                   exponents = exponents, \n",
    "                                                   dimension = self._dimension,\n",
    "                                                   models_name = self._models_name,\n",
    "                                                   models_func = self._models_func,\n",
    "                                                   n_per_class = n_per_class)       \n",
    "            \n",
    "        return data_models\n",
    "    \n",
    "    def _load_trajectories(self, T, exponents, dimension, \n",
    "                                models_name, n_per_class, \n",
    "                                path, N_save = 1000, t_save = 1000):\n",
    "        ''' Load trajectories from a h5py file of the given path. The name of the datasets in the\n",
    "        file have the following structure: \n",
    "            '(exponent with 2 digit_precision)_T_(lenght of trajectories in the dataset)_N_(number of trajectories in the dataset)'\n",
    "        Arguments: \n",
    "            :T (int):\n",
    "                - length of the trajectories.   \n",
    "            :exponents (array):\n",
    "                - anomalous exponents to include in the dataset. Allows for two digit precision.\n",
    "            :dimension (int):\n",
    "                - Dimensions of the generated trajectories. Three possible values: 1, 2 and 3.\n",
    "            :models_name (list of str):\n",
    "                - names of the models to include in the output dataset. \n",
    "            :n_per_class:\n",
    "                - number of trajectories to consider per exponent/model.\n",
    "            :path (str):\n",
    "                - path to the folder from where to load the trajectories dataset.\n",
    "            :t_save (int):\n",
    "                - length of the trajectories in the datasets to load.\n",
    "            :N_save (array):\n",
    "                - number of trajectories contained in the datasets to load.                  \n",
    "        Return:\n",
    "            :dataset (numpy.array):\n",
    "                - Dataset of trajectories of lenght (number of models)x(T+2), with the following structure:\n",
    "                    o First column: model label \n",
    "                    o Second column: value of the anomalous exponent\n",
    "                    o 2:T columns: trajectories'''\n",
    "                    \n",
    "        '''Establish dimensions and corresponding models'''\n",
    "        self._dimension = dimension\n",
    "        self._get_models()\n",
    "            \n",
    "        \n",
    "        if isinstance(models_name, int):\n",
    "            models_name = [models_name]\n",
    "               \n",
    "        for idx_m, name in enumerate(models_name):        \n",
    "            hf = h5py.File(path+name+'.h5', 'r+')\n",
    "            \n",
    "            for idx_e, exp  in enumerate(exponents):\n",
    "                \n",
    "                name_dataset = f'{exp:.2f}_T_{t_save}_N_'+ \\\n",
    "                                str(int(N_save[idx_m, idx_e]))+f'_dim_{self._dimension}'  \n",
    "                \n",
    "                n = int(n_per_class[idx_m, idx_e])\n",
    "                if n == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    data = (hf.get(name_dataset)[()][:n,:self._dimension*T]) \n",
    "                except:\n",
    "                    raise TypeError('The dataset you want to load does not exist.')\n",
    "                    \n",
    "                \n",
    "                data = self._label_trajectories(trajs = data, model_name = name, exponent = exp)                \n",
    "                            \n",
    "                if idx_e + idx_m == 0:\n",
    "                    dataset = data\n",
    "                else:\n",
    "                    dataset = np.concatenate((dataset, data), axis = 0) \n",
    "        return dataset\n",
    "     \n",
    "    def _save_trajectories(self, exponents, models_name, models_func, path, n_per_class,\n",
    "                          N_save = 1000, t_save = 1000, dimension = 1):\n",
    "        ''' Saves a dataset for the exponents and models considered. \n",
    "        Arguments:   \n",
    "            :exponents (array):\n",
    "                - anomalous exponents to include in the dataset. Allows for two digit precision.\n",
    "            :models_name (list of str):\n",
    "                - names of the models to include in the output dataset. \n",
    "            :models_func (list of funcs):\n",
    "                - function generating the models to include in the output dataset. \n",
    "            :path (str):\n",
    "                - path to the folder where to save the trajectories dataset.\n",
    "            :t_save (int):\n",
    "                - length of the trajectories to save in the datasets.\n",
    "            :N_save (array):\n",
    "                - number of trajectories to include in the datasets saved.\n",
    "            :dimension (int):\n",
    "                - Dimensions of the generated trajectories. Three possible values: 1, 2 and 3.\n",
    "        No return           '''     \n",
    "    \n",
    "        '''Establish dimensions and corresponding models'''\n",
    "        self._dimension = dimension\n",
    "        self._get_models()        \n",
    "        \n",
    "        for idx_m, (name, func) in enumerate(zip(models_name, models_func)):\n",
    "            \n",
    "            if os.path.isfile(path+name+'.h5'):\n",
    "                action = 'r+'\n",
    "            else:\n",
    "                action = 'w'\n",
    "            with h5py.File(path+name+'.h5', action) as hf:\n",
    "                \n",
    "                for idx_e, exp in enumerate(exponents): \n",
    "                    if n_per_class[idx_m, idx_e] == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    n = int(N_save[idx_m, idx_e])                    \n",
    "                    name_dataset = f'{exp:.2f}_T_{t_save}_N_{n}_dim_{self._dimension}' \n",
    "                    \n",
    "                    if name_dataset not in hf:  \n",
    "                        \n",
    "                        data = np.zeros((n, self._dimension*t_save))                           \n",
    "                        # TQDM variables\n",
    "                        tq = trange(n)\n",
    "                        tq.set_postfix(saving = True, model = name, exponent = exp)\n",
    "                        for i in tq:\n",
    "                            data[i, :] = func(t_save, exp)                           \n",
    "                            \n",
    "                        hf.create_dataset(name_dataset, data=data)\n",
    "                        \n",
    "                    else:\n",
    "                        print(f'The dataset for {name} with exponent {round(exp,3)}'\n",
    "                                +' already exists, no need of saving it again.')\n",
    "            \n",
    "        \n",
    "    def _create_trajectories(self, T, exponents, dimension, models_name, models_func, n_per_class):  \n",
    "        ''' create a dataset for the exponents and models considered. \n",
    "        Arguments:  \n",
    "            :T (int):\n",
    "                - length of the trajectories.   \n",
    "            :exponents (array):\n",
    "                - anomalous exponents to include in the dataset. Allows for two digit precision.\n",
    "            :dimension (int):\n",
    "                - Dimensions of the generated trajectories. Three possible values: 1, 2 and 3.\n",
    "            :models_name (list of str):\n",
    "                - names of the models to include in the output dataset. \n",
    "            :models_func (list of funcs):\n",
    "                - function generating the models to include in the output dataset. \n",
    "            :n_per_class:\n",
    "                - number of trajectories to consider per exponent/model. \n",
    "        Return:\n",
    "            :dataset (numpy.array):\n",
    "                - Dataset of trajectories of lenght (number of models)x(T+2), with the following structure:\n",
    "                    o First column: model label.\n",
    "                    o Second column: value of the anomalous exponent.\n",
    "                    o 2:T columns: trajectories.'''\n",
    "            \n",
    "        for idx_m, (name, func) in enumerate(zip(models_name, models_func)):\n",
    "            for idx_e, exp in enumerate(exponents):\n",
    "                \n",
    "                \n",
    "                n = int(n_per_class[idx_m, idx_e])\n",
    "                data = np.zeros((n, self._dimension*T))  \n",
    "                for i in range(n):\n",
    "                    data[i, :] = func(T, exp)\n",
    "                    \n",
    "                data = self._label_trajectories(trajs = data, model_name = name, exponent = exp)   \n",
    "                \n",
    "                if idx_e + idx_m == 0:\n",
    "                    dataset = data\n",
    "                else:\n",
    "                    dataset = np.concatenate((dataset, data), axis = 0)\n",
    "                \n",
    "        return dataset\n",
    "                \n",
    "            \n",
    "    def _label_trajectories(self, trajs, model_name, exponent):\n",
    "        ''' Labels given trajectories given the corresponding label for the model and exponent.\n",
    "        For models, the label correspond to the position of the model in self.avail_models_name.\n",
    "        For exponents, the label if the value of the exponent.\n",
    "        Arguments:\n",
    "            :trajs (numpy array):\n",
    "                - trajectories to label\n",
    "            :model_name (str):\n",
    "                - name of the model from which the trajectories are coming from.\n",
    "            :exponent (float):\n",
    "                - Anomalous exponent of the trajectories. \n",
    "        Return:\n",
    "            :trajs (numpy array):\n",
    "                - Labelled trajectoreis, with the following structure:\n",
    "                    o First column: model label\n",
    "                    o Second columnd: exponent label\n",
    "                    o Rest of the array: trajectory.   '''\n",
    "        \n",
    "        label_model = self.avail_models_name.index(model_name)          \n",
    "         \n",
    "        labels_mod = np.ones((trajs.shape[0], 1))*label_model\n",
    "        labels_alpha = np.ones((trajs.shape[0], 1))*exponent\n",
    "        trajs = np.concatenate((labels_mod, labels_alpha, trajs), axis = 1)\n",
    "        \n",
    "        return trajs\n",
    "\n",
    "    def create_noisy_localization_dataset(self, \n",
    "                                          dataset = False,\n",
    "                                          T = False, N = False, exponents = False, models = False, dimension = 1,\n",
    "                                          noise_func = False, sigma = 1, mu = 0,\n",
    "                                          save_trajectories = False, load_trajectories = False, \n",
    "                                          path = 'datasets/',\n",
    "                                          N_save = 1000, t_save = 1000): \n",
    "        ''' Create a dataset of noisy trajectories. This function creates trajectories with _create_trajectories\n",
    "        and then adds given noise to them.        \n",
    "        Arguments: All arguments are the same as _create_trajectories but noise_func\n",
    "            :dataset (bool, numpy array):\n",
    "                - If False, creates a dataset with the given parameters. If numpy array, dataset to which the\n",
    "                  function applies the noise.\n",
    "            :noise_func (bool, function):\n",
    "                - if False, the noise added to the trajectories will be Gaussian distributed, with \n",
    "                  variance sigma and mean value mu.\n",
    "                - if function, uses the given function to generate noise to be added to the trajectory. The \n",
    "                  function must have as input two ints, N and M and the output must be a matrix of size NxM.\n",
    "        Return:\n",
    "            :data_models (numpy.array):\n",
    "                - Dataset of trajectories of lenght Nx(T+2), with the following structure:\n",
    "                    o First column: model label \n",
    "                    o Second column: value of the anomalous exponent\n",
    "                    o 2:T columns: trajectories'''\n",
    "                    \n",
    "        if not dataset.any():\n",
    "            dataset = self.create_dataset(T, N, exponents, models, dimension,\n",
    "                                                     save_trajectories, load_trajectories, \n",
    "                                                     path,\n",
    "                                                     N_save, t_save)\n",
    "            \n",
    "        # Add the noise to the trajectories  \n",
    "        trajs = dataset[:, 2:].reshape(dataset.shape[0]*dimension, T)\n",
    "        trajs = self._add_noisy_localization(trajs, noise_func, sigma, mu)\n",
    "        \n",
    "        dataset[:, 2:] = trajs.reshape(dataset.shape[0], T*dimension)\n",
    "        \n",
    "        return dataset    \n",
    "    \n",
    "    def create_noisy_diffusion_dataset(self, \n",
    "                                       dataset = False,\n",
    "                                       T = False, N = False, exponents = False, models = False, dimension = 1,\n",
    "                                       diffusion_coefficients = False,\n",
    "                                       save_trajectories = False, load_trajectories = False, \n",
    "                                       path = 'datasets/',\n",
    "                                       N_save = 1000, t_save = 1000): \n",
    "        ''' \n",
    "        Create a dataset of noisy trajectories. This function creates trajectories with `_create_trajectories`\n",
    "        and then adds given noise to them.        \n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        All arguments are the same as `_create_trajectories` but dataset and diffusion_coefficients\n",
    "            :dataset (bool, numpy array):\n",
    "                - If False, creates a dataset with the given parameters. If numpy array, dataset to which the\n",
    "                  function applies the noise.\n",
    "            :noise_func (bool, function):\n",
    "                - if False, the noise added to the trajectories will be Gaussian distributed, with \n",
    "                  variance sigma and mean value mu.\n",
    "                - if function, uses the given function to generate noise to be added to the trajectory. The \n",
    "                  function must have as input two ints, N and M and the output must be a matrix of size NxM.\n",
    "                 - if numpy array, sums it to the trajectories\n",
    "        Returns\n",
    "        --------\n",
    "            :data_models (numpy.array):\n",
    "                - Dataset of trajectories of lenght Nx(T+2), with the following structure:\n",
    "                    o First column: model label \n",
    "                    o Second column: value of the anomalous exponent\n",
    "                    o 2:T columns: trajectories'''\n",
    "                    \n",
    "        if not dataset.any():\n",
    "            dataset = self.create_dataset(T, N, exponents, models, dimension,\n",
    "                                                     save_trajectories, load_trajectories, \n",
    "                                                     path,\n",
    "                                                     N_save, t_save)\n",
    "        # Add the noise to the trajectories \n",
    "        trajs = dataset[:, 2:].reshape(dataset.shape[0]*dimension, T)\n",
    "        trajs = self._add_noisy_diffusion(trajs, diffusion_coefficients)\n",
    "        \n",
    "        dataset[:, 2:] = trajs.reshape(dataset.shape[0], T*dimension)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_noisy_localization(trajs, noise_func = False, sigma = 1, mu = 0):\n",
    "        \n",
    "        if isinstance(noise_func, np.ndarray):\n",
    "            noise_matrix = noise_func \n",
    "        elif not noise_func:\n",
    "            noise_matrix = sigma*np.random.randn(trajs.shape[0], trajs.shape[1])+mu\n",
    "        elif hasattr(noise_func, '__call__'):\n",
    "            noise_matrix = noise_func(trajs.shape[0], trajs.shape[1])             \n",
    "        else:\n",
    "            raise ValueError('noise_func has to be either False for Gaussian noise, a Python function or numpy array.')\n",
    "        \n",
    "        trajs += noise_matrix \n",
    "        \n",
    "        return trajs\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_noisy_diffusion(trajs, diffusion_coefficients = False):\n",
    "        \n",
    "        # First normalize the trajectories\n",
    "        trajs = normalize(trajs)\n",
    "        # If no new diffusion coefficients given, create new ones randonmly\n",
    "        if not diffusion_coefficients:\n",
    "            diffusion_coefficients = np.random.randn(trajs.shape[0])\n",
    "        # Apply new diffusion coefficients\n",
    "        trajs = (trajs.transpose()*diffusion_coefficients).transpose()\n",
    "        \n",
    "        return trajs\n",
    "\n",
    "    @staticmethod\n",
    "    def create_segmented_dataset(dataset1, dataset2, dimension = 1, \n",
    "                                 final_length = 200, random_shuffle = False):\n",
    "        ''' \n",
    "        Creates a dataset with trajectories which change diffusive feature (either model or anomalous exponent) after a time 't_change'. \n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "            :dataset1 (numpy.array):\n",
    "                - array of size Nx(t+2), where the first columns values correspond\n",
    "                to the labels of the model and anomalous exponent. The rest \n",
    "                correspond to the trajectories of length t.\n",
    "            :dataset2 (numpy.array):\n",
    "                - same as dataset1\n",
    "            :dimension (int):\n",
    "                - Dimensions of the generated trajectories. Three possible values: 1, 2 and 3.\n",
    "            :final_length (int):\n",
    "                - length of the output trajectories.\n",
    "            :random_shuffle (bool):\n",
    "                - If True, shuffles the first axis of dataset1 and dataset2.\n",
    "        Returns\n",
    "        ---------\n",
    "            :seg_dataset (numpy.array):\n",
    "                - array of size Nx(t+5) whose columns represent:\n",
    "                    o Column 0: changing time\n",
    "                    o Column 1,2: labels first part of the trajectory (model, exponent)\n",
    "                    o Column 3,4: labels second part of the trajectory (model, exponent)\n",
    "                    o Column 5:(t+5): trajectories of lenght t.\n",
    "        '''\n",
    "                    \n",
    "        '''Establish dimensions and corresponding models'''                    \n",
    "        \n",
    "        if dataset1.shape[0] != dataset2.shape[0]:\n",
    "            raise ValueError(f'Input datasets must have the same number of trajectories. Current ones have size {dataset1.shape[0]} and {dataset2.shape[0]}.')\n",
    "        if dataset1.shape[1]-2 < final_length or dataset2.shape[1]-2 < final_length:\n",
    "            raise ValueError(f'The trajectories in the input datasets are too short. They must be at least {final_length} steps long.')\n",
    "        \n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(dataset1)\n",
    "            np.random.shuffle(dataset2)\n",
    "        \n",
    "        n_trajs = dataset1.shape[0]\n",
    "        trajs_1 = np.copy(dataset1[:, 2:].reshape(n_trajs, dimension, int((dataset1.shape[1]-2)/dimension)))\n",
    "        trajs_2 = np.copy(dataset2[:, 2:].reshape(n_trajs, dimension, int((dataset2.shape[1]-2)/dimension)))\n",
    "\n",
    "        trajs_1 = trajs_1[:, :, :final_length]\n",
    "        trajs_2 = trajs_2[:, :, :final_length]\n",
    "\n",
    "        t_change = np.random.randint(1, final_length, n_trajs)\n",
    "\n",
    "        seg_dataset = np.zeros((n_trajs, dimension*final_length+5))\n",
    "        for idx, (tC, traj1, traj2, label1, label2) in enumerate(zip(t_change, \n",
    "                                                                      trajs_1, trajs_2,\n",
    "                                                                      dataset1[:, :2], dataset2[:, :2])):\n",
    "            seg_dataset[idx, 0] = tC\n",
    "            seg_dataset[idx, 1:5] = np.append(label1, label2)\n",
    "\n",
    "            if dimension == 1:\n",
    "                seg_dataset[idx, 5:tC+5] = traj1[:, :tC]\n",
    "                seg_dataset[idx, tC+5:] = traj2[:, tC:final_length]-traj2[:, tC]+traj1[:, tC]\n",
    "\n",
    "            elif dimension == 2 or dimension == 3:\n",
    "                traj2 = (traj2.transpose()-traj2[:, tC]+traj1[:, tC]).transpose()\n",
    "\n",
    "                traj1[:,tC:]  = 0\n",
    "                traj2[:, :tC] = 0\n",
    "\n",
    "                seg_dataset[idx, 5:] = (traj1 + traj2).reshape(dimension*final_length)            \n",
    "            \n",
    "        return seg_dataset\n",
    "    \n",
    "    @staticmethod\n",
    "    def _save_row(data, file):\n",
    "        '''Auxiliary function to save append data in existing files using csv\n",
    "        Arguments:\n",
    "            :data (numpy.array):\n",
    "                - row to be appended to the filed\n",
    "            :file (str):\n",
    "                - file where to append data.'''\n",
    "        with open(file, 'a') as f:\n",
    "            writer = csv.writer(f, delimiter=';', lineterminator='\\n',)\n",
    "            writer.writerow(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cut_trajectory(traj, t_cut, dim=1):\n",
    "        \"Takes a trajectory and cuts it to `t_cut` length.\"\n",
    "        cut_traj = traj.reshape(dim, -1)[:, :t_cut]\n",
    "        return cut_traj.reshape(-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d19a7-8784-4a7d-92a8-01fcc61bf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(datasets_theory().create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebe4fa-294a-4e40-8353-ef8e5bab7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(datasets_theory().create_segmented_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f63bc-13c0-426f-8f46-d5fa6086c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(datasets_theory().create_noisy_diffusion_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28d1f6-0541-4798-953f-54bf712bca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
