{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b0092b-72fc-4fc0-b0c8-de00e3238687",
   "metadata": {},
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d422d-1eba-4bab-b437-f66ed7cafc54",
   "metadata": {},
   "source": [
    "Here we gather a collection of tutorials for different parts of this library. You can access all the notebooks in our [repo](https://github.com/AnDiChallenge/andi_datasets/tree/master/source_nbs/tutorials).\n",
    "\n",
    "## AnDi 1 challenge:\n",
    "\n",
    "1. [Theory models and AnDi 1](challenge_one_datasets.ipynb): this tutorials introduced the theoretical models contained in this library, as well as the generation of datasets for the AnDi 2020 challenge.\n",
    "\n",
    "2. [AnDi 1 submission: from trajectories to predictions](challenge_one_submission.ipynb): this tutorial shows how to manage the datasets given in the AnDi 2020 challenge and shows how to do predictions both with an statistical approach as with machine learning method.\n",
    "\n",
    "## AnDi 2 challenge:\n",
    "\n",
    "1. [Phenom models and AnDi 2](challenge_two_datasets.ipynb): this tutorial overviews the phenomenological models contained in the library.\n",
    "\n",
    "2. [Creating videos tutorial](creating_videos_phenom.ipynb): this tutorial shows how to generate videos using combining the [`deep-track`](https://github.com/softmatterlab/DeepTrack2) library together with `andi-datasets`.\n",
    "\n",
    "3. [AnDi 2: from the data to the submission](challenge_two_submission.ipynb): here we showcase how to read the data of the challenge, create a submission but also how to generate your own data.\n",
    "\n",
    "4. [Benchmark dataset](challenge_two_benchmark.ipynb): create and load the AnDi 2 benchmark dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
