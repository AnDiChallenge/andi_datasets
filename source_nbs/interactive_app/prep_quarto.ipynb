{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp interactive_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnDi Challenge 2020 - Interactive tool\n",
    "\n",
    "Explore the results of the AnDi challenge 2020 interactively. Here you will find access to the details of each submissions results over the different features of the dataset. \n",
    "This tab showcases a summary of the results of Task 1 and Task 2. The rest of the tabs corresponds to each of the tasks separatedely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import curdoc, show, output_notebook\n",
    "from bokeh.layouts import row,gridplot,grid, column\n",
    "from bokeh.models import ColumnDataSource, RadioButtonGroup, Select, Text, Slider, RangeSlider, PreText, FileInput, LinearColorMapper, HoverTool, Label, Span, Div\n",
    "from bokeh.events import Tap\n",
    "from bokeh.application import Application\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.palettes import Category10 as palette\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.tile_providers import OSM, get_provider\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import io\n",
    "\n",
    "from pybase64 import b64decode\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "processes = ['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n",
    "processes_simp = ['a','c','f','l','s']\n",
    "dims = [\"1D\", \"2D\", \"3D\"]\n",
    "colors_ROC = palette[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Checks if we are in notebook or .py and executes correct dfs\n",
    "try:\n",
    "    __IPYTHON__\n",
    "    \n",
    "    df_t1 = [pd.read_csv(f'csv/task1_{dim}d.csv') for dim in [1,2,3]]\n",
    "    df_t2 = [pd.read_csv(f'csv/task2_{dim}d.csv') for dim in [1,2,3]]\n",
    "    df_t3 = [pd.read_csv(f'csv/task3_{dim}d.csv') for dim in [1,2,3]]\n",
    "\n",
    "    df_t1_results = [pd.read_csv(f'csv/results_parameters_task1_{dim}D.csv') for dim in [1,2,3]]\n",
    "    df_t2_results = [pd.read_csv(f'csv/results_parameters_task2_{dim}D.csv') for dim in [1,2,3]]\n",
    "    \n",
    "    notebook = True\n",
    "\n",
    "except NameError:\n",
    "    \n",
    "    df_t1 = [pd.read_csv(f'source_nbs/interactive_app/csv/task1_{dim}d.csv') for dim in [1,2,3]]\n",
    "    df_t2 = [pd.read_csv(f'source_nbs/interactive_app/csv/task2_{dim}d.csv') for dim in [1,2,3]]\n",
    "    df_t3 = [pd.read_csv(f'source_nbs/interactive_app/csv/task3_{dim}d.csv') for dim in [1,2,3]]\n",
    "\n",
    "    df_t1_results = [pd.read_csv(f'source_nbs/interactive_app/csv/results_parameters_task1_{dim}D.csv') for dim in [1,2,3]]\n",
    "    df_t2_results = [pd.read_csv(f'source_nbs/interactive_app/csv/results_parameters_task2_{dim}D.csv') for dim in [1,2,3]]\n",
    "    \n",
    "    notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#| hide \n",
    "def updated_preds(df, team, model = None, a_min = None, a_max = None, l_min = 0, l_max = 1000, loc = 'All'):\n",
    "    # Exponent\n",
    "    if a_min != None:\n",
    "        df = df.loc[lambda df: (df['alpha'] >= a_min) & (df['alpha'] <= a_max)]\n",
    "    # Length\n",
    "    df = df.loc[lambda df: (df['length'] >= l_min) & (df['length'] <= l_max)]\n",
    "    # Model\n",
    "    if model != 'All' and model != None:\n",
    "        model = processes.index(model)\n",
    "        df = df.loc[lambda df: (df['model'] == model)]\n",
    "    # Localization\n",
    "    if loc != 'All':\n",
    "        loc = float(loc)\n",
    "        df = df.loc[lambda df: (df['loc_error'] == loc)]    \n",
    "    return df[team]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#| hide \n",
    "def update_t1():\n",
    "    # Data\n",
    "    preds = updated_preds(df = df_t1[dims.index(dim_select_t1.value)], \n",
    "              model = model_group.value, \n",
    "              a_min = alpha_slider_t1.value[0],\n",
    "              a_max = alpha_slider_t1.value[1],\n",
    "              l_min = length_slider_t1.value[0],\n",
    "              l_max = length_slider_t1.value[1],\n",
    "              loc = noise_group_t1.value,\n",
    "              team = team_select_t1.value)      \n",
    "    \n",
    "    if preds.shape[0] == 0:\n",
    "         # If there are no enough trajectories\n",
    "        div_t1_aux.text = f\"\"\"\n",
    "        <p style=\"color:red\">  <b>Warning!</b> <br> Not enough trajectories. Select wider option ranges.</p>\"\"\"\n",
    "        return\n",
    "    \n",
    "    trues = df_t1[dims.index(dim_select_t1.value)]['alpha'][preds.index]\n",
    "    # hist 2d\n",
    "    fig_exp.renderers = []\n",
    "    r, bins = fig_exp.hexbin(trues, \n",
    "                             preds, \n",
    "                             size=0.05, hover_color=\"pink\", hover_alpha=0.8, palette='Viridis256')\n",
    "    # kde \n",
    "    fig_kde.renderers = []\n",
    "    data = (preds-trues).values\n",
    "    density = gaussian_kde(data)\n",
    "    hist, edges = np.histogram(data, density=True, bins=50)\n",
    "    fig_kde.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], fill_color = '#440154', line_color=\"white\", alpha = 0.5)\n",
    "    xs = np.linspace(edges[0],edges[-1],100)\n",
    "    fig_kde.line(xs, density(xs), line_color = '#79D151', line_width = 3)\n",
    "    \n",
    "    #MAE vs MOD\n",
    "    fig_mod.renderers = []\n",
    "    mae_vs_mod(fig_mod)\n",
    "    \n",
    "    # Text\n",
    "    div_t1_aux.text = f\"\"\"\n",
    "    <b>Prediction summary </b>     \n",
    "    <br>\n",
    "    Number trajs. = {len(trues)}\n",
    "    <br>\n",
    "    MAE = {round((preds-trues).abs().mean(),3)}\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "def mae_vs_mod(fig):    \n",
    "    kwargs = {'df' : df_t1[dims.index(dim_select_t1.value)],\n",
    "              'a_min' : alpha_slider_t1.value[0], 'a_max' : alpha_slider_t1.value[1],\n",
    "              'l_min' : length_slider_t1.value[0],'l_max' : length_slider_t1.value[1],\n",
    "              'loc' : noise_group_t1.value,\n",
    "              'team' : team_select_t1.value}\n",
    "    mae_mod = []\n",
    "    if model_group.value != 'All':\n",
    "        pr = [model_group.value]\n",
    "    else:\n",
    "        if alpha_slider_t1.value[0] > 1:\n",
    "            pr = np.delete(processes, [0,1])\n",
    "        elif alpha_slider_t1.value[1] < 1:\n",
    "            pr = np.delete(processes, 3)\n",
    "        elif alpha_slider_t1.value[0] == 2:\n",
    "            pr = np.delete(processes, [0,1,2])\n",
    "        else:\n",
    "            pr = processes\n",
    "        \n",
    "    for idx, mod in enumerate(pr):\n",
    "        preds = updated_preds(model = mod, **kwargs)\n",
    "        trues = df_t1[dims.index(dim_select_t1.value)]['alpha'][preds.index]\n",
    "        mae_mod.append(np.abs((preds-trues).values).mean())\n",
    "        \n",
    "    fig.circle(pr, mae_mod, size = 10, color = '#440154')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4196\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"4196\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"4196\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"4196\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"4196\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "<script id=\"4321\">\n",
       "  (function() {\n",
       "    const xhr = new XMLHttpRequest()\n",
       "    xhr.responseType = 'blob';\n",
       "    xhr.open('GET', \"http://localhost:58478/autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none\", true);\n",
       "    xhr.onload = function (event) {\n",
       "      const script = document.createElement('script');\n",
       "      const src = URL.createObjectURL(event.target.response);\n",
       "      script.src = src;\n",
       "      document.body.appendChild(script);\n",
       "    };\n",
       "    xhr.send();\n",
       "  })();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "bc46ba18a5bd420c8befbe1b9147f890"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.application:Uncaught exception GET /autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:58478', method='GET', uri='/autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\tornado\\web.py\", line 1704, in _execute\n",
      "    result = await result\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\views\\autoload_js_handler.py\", line 62, in get\n",
      "    session = await self.get_session()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\views\\session_handler.py\", line 144, in get_session\n",
      "    session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\contexts.py\", line 243, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\application\\application.py\", line 194, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\application\\handlers\\function.py\", line 143, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"C:\\Users\\Gorka\\AppData\\Local\\Temp\\ipykernel_8452\\3428397898.py\", line 82, in modify_doc\n",
      "    doc.add_root(row(l1, width=10))\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\document.py\", line 327, in add_root\n",
      "    with self.models.freeze():\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 135, in freeze\n",
      "    self._pop_freeze()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 276, in _pop_freeze\n",
      "    self.recompute()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 224, in recompute\n",
      "    ma._attach_document(document)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\model\\model.py\", line 580, in _attach_document\n",
      "    raise RuntimeError(f\"Models must be owned by only a single document, {self!r} is already in a doc\")\n",
      "RuntimeError: Models must be owned by only a single document, BasicTicker(id='4215', ...) is already in a doc\n",
      "ERROR:tornado.access:500 GET /autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none (::1) 50.14ms\n",
      "ERROR:tornado.application:Uncaught exception GET /autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:58478', method='GET', uri='/autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\tornado\\web.py\", line 1704, in _execute\n",
      "    result = await result\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\views\\autoload_js_handler.py\", line 62, in get\n",
      "    session = await self.get_session()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\views\\session_handler.py\", line 144, in get_session\n",
      "    session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\server\\contexts.py\", line 243, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\application\\application.py\", line 194, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\application\\handlers\\function.py\", line 143, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"C:\\Users\\Gorka\\AppData\\Local\\Temp\\ipykernel_8452\\3428397898.py\", line 82, in modify_doc\n",
      "    doc.add_root(row(l1, width=10))\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\document.py\", line 327, in add_root\n",
      "    with self.models.freeze():\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 135, in freeze\n",
      "    self._pop_freeze()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 276, in _pop_freeze\n",
      "    self.recompute()\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\document\\models.py\", line 224, in recompute\n",
      "    ma._attach_document(document)\n",
      "  File \"C:\\Users\\Gorka\\anaconda3\\lib\\site-packages\\bokeh\\model\\model.py\", line 580, in _attach_document\n",
      "    raise RuntimeError(f\"Models must be owned by only a single document, {self!r} is already in a doc\")\n",
      "RuntimeError: Models must be owned by only a single document, BasicTicker(id='4215', ...) is already in a doc\n",
      "ERROR:tornado.access:500 GET /autoload.js?bokeh-autoload-element=4321&bokeh-absolute-url=http://localhost:58478&resources=none (::1) 41.70ms\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "\n",
    "# init bokeh\n",
    "output_notebook()\n",
    "\n",
    "# Widgets\n",
    "dim_select_t1 = Select(value=\"1D\", options=dims, title = 'Dimensions')\n",
    "team_select_t1 = Select(value=df_t1[0].keys()[6:].tolist()[0], options=df_t1[0].keys()[6:].tolist(), title = 'Team')\n",
    "alpha_slider_t1 = RangeSlider(start=0, end=2, value=(0, 2), step=.05, title=r\"Anomalous exponent\")\n",
    "length_slider_t1 = RangeSlider(start=10, end=1000, value=(10, 1000), step=1, title=r\"Length\")\n",
    "model_group = Select(options=['All']+[p for p in processes], value=\"All\", title ='Diffusion model')\n",
    "noise_group_t1 = Select(options=['All']+[str(n) for n in np.unique(df_t1[0].loc_error)[::-1]], value=\"All\", title ='Signal to Noise ratio (SNR)')\n",
    "\n",
    "# Text\n",
    "div_t1 = Div(text= \"\"\" <h2>Task 1 - Inference of the anomalous diffusion exponent</h2>\n",
    "\n",
    "The goal of this task is to extract the anomalous diffusion exponent, usually defined as the scaling exponent of the ensemble averaged mean squared displacement w.r.t to time. \n",
    "The central figure shows a 2D histogram comparing the predicted and ground-truth exponents. \n",
    "The upper-rightmost figure shows the histogram over the difference between these two. \n",
    "The lower-rightmost figure shows the MAE of the method for each diffusion model.\n",
    "\"\"\", width = 1000, margin = (0,0,20,0))\n",
    "\n",
    "div_t1_aux = Div(text= \"asd\", width = 220)\n",
    "\n",
    "\n",
    "# Plots\n",
    "size_t1 = 500\n",
    "fig_exp = figure(tools=\"pan,wheel_zoom,reset\", \n",
    "                 match_aspect=True, \n",
    "                 background_fill_color='#440154', \n",
    "                 x_range = [0,2.05], y_range = [0,2.05],\n",
    "                 x_axis_label = 'True exponent', y_axis_label = 'Predicted exponent',\n",
    "                 plot_height = size_t1, plot_width = size_t1, margin=(0, 20, 0, 20))\n",
    "fig_exp.grid.visible = False\n",
    "# fig_exp.background_fill_color=None\n",
    "\n",
    "fig_kde = figure(y_axis_label = 'Frequency',\n",
    "                 x_axis_label = r'Difference between predicted and true exponents',\n",
    "                 plot_height = int(size_t1/1.7),\n",
    "                 x_range = [-1, 1],\n",
    "                 plot_width = size_t1,\n",
    "                 margin = (0,0,20,0))\n",
    "fig_kde.background_fill_color=None\n",
    "\n",
    "fig_mod = figure(y_axis_label = 'MAE',\n",
    "                 x_axis_label = r'Diffusion model', \n",
    "                 x_range=processes, \n",
    "                 plot_height = int(size_t1/2.7), \n",
    "                 plot_width = size_t1 )\n",
    "fig_mod.background_fill_color=None\n",
    "\n",
    "# Updates\n",
    "update_t1()\n",
    "\n",
    "def update_select_team_t1(attrname, old, new):\n",
    "    team_select_t1.options = df_t1[dims.index(dim_select_t1.value)].keys()[6:].tolist()  \n",
    "    team_select_t1.value = team_select_t1.options[0]    \n",
    "    \n",
    "    noise_group_t1.options = ['All']+[str(n) for n in np.unique(df_t1[dims.index(dim_select_t1.value)].loc_error)[::-1]]\n",
    "    noise_group_t1.value = 'All'\n",
    "    \n",
    "    update_t1()\n",
    "\n",
    "controls_t1 = [dim_select_t1, team_select_t1, model_group, noise_group_t1]\n",
    "for control in controls_t1:\n",
    "    control.on_change('value', lambda attr, old, new: update_t1() )\n",
    "    \n",
    "sliders_t1 = [alpha_slider_t1, length_slider_t1]\n",
    "for control in sliders_t1:\n",
    "    control.on_change('value_throttled', lambda attr, old, new: update_t1())\n",
    "all_controls_t1 = controls_t1+sliders_t1\n",
    "\n",
    "dim_select_t1.on_change('value', update_select_team_t1)\n",
    "\n",
    "# Layout\n",
    "inputs_t1 = column(*all_controls_t1+[div_t1_aux], width = 220, height = 500)\n",
    "\n",
    "l1 = grid([div_t1,\n",
    "           row(inputs_t1, fig_exp, column(fig_kde, fig_mod))])\n",
    "\n",
    "def modify_doc(doc):\n",
    "    doc.add_root(row(l1, width=10))\n",
    "\n",
    "handler = FunctionHandler(modify_doc)\n",
    "app = Application(handler)\n",
    "show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "def conf_mat(true, pred, p):\n",
    "    conf = confusion_matrix(true, pred, normalize = 'true', labels = [0,1,2,3,4])\n",
    "    tn, pn, alpha, color, posx, posy, text = [], [], [], [], [], [], []\n",
    "\n",
    "    for idxt, true in enumerate(processes):\n",
    "        for idxp, pred in enumerate(processes):\n",
    "            tn.append(true)\n",
    "            pn.append(pred)\n",
    "            alpha.append(conf[idxt, idxp])\n",
    "            color.append('#FF5733')\n",
    "            posx.append(idxt+0.4)\n",
    "            posy.append(4-idxp+0.4)\n",
    "            text.append(str(round(conf[idxt, idxp],2)))\n",
    "\n",
    "\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(predicted=pn, actual=tn, count=conf.flatten(), colors = color, alphas = alpha, posx = posx, posy = posy, text = text)\n",
    "    )\n",
    "    p.plot_width = 600\n",
    "    p.plot_height = p.plot_width\n",
    "    rectwidth = 0.9\n",
    "    p.rect('actual','predicted', rectwidth, rectwidth, source=source,\n",
    "          color='colors', alpha='alphas',line_width=1)\n",
    "    glyph = Text(x=\"posx\", y=\"posy\", text=\"text\", text_color = '#000000')\n",
    "    p.add_glyph(source, glyph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "def ROC(fig):       \n",
    "\n",
    "    preds = updated_preds_t2_probs(df = df_t2[dims.index(dim_select_t2.value)],\n",
    "                                  a_min = alpha_slider_t2.value[0],\n",
    "                                  a_max = alpha_slider_t2.value[1],\n",
    "                                  l_min = length_slider_t2.value[0],\n",
    "                                  l_max = length_slider_t2.value[1],\n",
    "                                  loc = noise_group_t2.value,\n",
    "                                  team = team_select_t2.value)       \n",
    "    trues = df_t2[dims.index(dim_select_t2.value)]['model'][preds.index] \n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(trues.values)\n",
    "\n",
    "    y_test = lb.transform(trues.values)\n",
    "    y_score = preds.to_numpy()[:,np.unique(trues.values).astype(int)]\n",
    "\n",
    "    classes = np.unique(trues.values).astype(int)\n",
    "    n_classes = len(classes)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    source_macro = ColumnDataSource(data=dict(fpr_mac = fpr[\"macro\"], tpr_mac = tpr[\"macro\"]))\n",
    "    source_micro = ColumnDataSource(data=dict(fpr_mic = fpr[\"micro\"], tpr_mic = tpr[\"micro\"]))\n",
    "\n",
    "    \n",
    "    for i, clas in enumerate(classes):\n",
    "        fig.line(fpr[i], tpr[i], color = colors_ROC[clas], legend_label = processes[clas], line_width = 2)\n",
    "    fig.line(x=\"fpr_mac\", y=\"tpr_mac\", source=source_macro, color = 'black', line_width = 2, legend_label = 'Macro')\n",
    "    fig.line(x=\"fpr_mic\", y=\"tpr_mic\", source=source_micro, color = 'black', line_dash = 'dashed', line_width = 2, legend_label = 'Micro')\n",
    "    fig.legend.location = \"bottom_right\"\n",
    "    \n",
    "    return roc_auc['micro']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "def updated_preds_t2_probs(df, team, a_min = None, a_max = None, l_min = 0, l_max = 1000, loc = 'All'):\n",
    "    # Exponent\n",
    "    if a_min != None:\n",
    "        df = df.loc[lambda df: (df['alpha'] >= a_min) & (df['alpha'] <= a_max)]\n",
    "    # Length\n",
    "    df = df.loc[lambda df: (df['length'] >= l_min) & (df['length'] <= l_max)]\n",
    "    # Localization\n",
    "    if loc != 'All':\n",
    "        loc = float(loc)\n",
    "        df = df.loc[lambda df: (df['loc_error'] == loc)]  \n",
    "        \n",
    "    filter_col = [col for col in df if col.startswith(team+'_')]\n",
    "    \n",
    "    return df[filter_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#| hide\n",
    "def update_t2():\n",
    "    # Data\n",
    "    preds = updated_preds(df = df_t2[dims.index(dim_select_t2.value)], \n",
    "          a_min = alpha_slider_t2.value[0],\n",
    "          a_max = alpha_slider_t2.value[1],\n",
    "          l_min = length_slider_t2.value[0],\n",
    "          l_max = length_slider_t2.value[1],\n",
    "          loc = noise_group_t2.value,\n",
    "          team = team_select_t2.value)\n",
    "    \n",
    "    if preds.shape[0] == 0:\n",
    "         # If there are no enough trajectories\n",
    "        div_t2_aux.text = f\"\"\"\n",
    "        <p style=\"color:red\">  <b>Warning!</b> <br> Not enough trajectories. Select wider option ranges.</p>\"\"\"\n",
    "        return\n",
    "\n",
    "    trues = df_t2[dims.index(dim_select_t2.value)]['model'][preds.index] \n",
    "    # Confusion matrix\n",
    "    fig_conf.renderers = []\n",
    "    conf_mat(trues, preds, fig_conf)  \n",
    "    # ROC\n",
    "    fig_roc.renderers = []   \n",
    "    fig_roc.legend.items = []\n",
    "    auc = ROC(fig_roc)\n",
    "    # Text\n",
    "    div_t2_aux.text = f\"\"\" <b>Prediction summary </b>     \n",
    "    <br>\n",
    "    Number trajs. = {len(trues)} \n",
    "    <br>\n",
    "    F1-score = {round(f1_score(trues, preds, average = 'micro'),3)}\n",
    "    <br>\n",
    "    AUC = {round(auc,2)}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "# Widgets\n",
    "dim_select_t2 = Select(value=\"1D\", options=dims, title = 'Dimension')\n",
    "teams_t2 = [s.split('_')[0] for s in df_t2[0].keys()[6:].tolist()][0:-1:6]\n",
    "team_select_t2 = Select(value=teams_t2[0], options=teams_t2, title = 'Team')\n",
    "alpha_slider_t2 = RangeSlider(start=0, end=2, value=(0, 2), step=.05, title=r\"Anomalous exponent\")\n",
    "length_slider_t2 = RangeSlider(start=10, end=1000, value=(10, 1000), step=1, title=r\"Length\")\n",
    "noise_group_t2 = Select(options=['All']+[str(n) for n in np.unique(df_t2[0].loc_error)[::-1]], value=\"All\", title ='Signal to Noise ratio (SNR)')\n",
    "\n",
    "\n",
    "# Text\n",
    "div_t2 = Div(text= f\"\"\" <h2>Task 2 - Diffusion model classification</h2>\n",
    "\n",
    "The goal of this task is to classify the trajectories among five diffusion models.\n",
    "The central figure shows the confusion matrix of the method. \n",
    "The rightmost figure shows the receiving operator curve (ROC) for each model and both micro and macro averaged.\n",
    "\"\"\", width = 1000, margin = (0,0,20,0))\n",
    "\n",
    "div_t2_aux = Div(text= \"\" , width = 220)\n",
    "\n",
    "# Plots\n",
    "size_t2 = 500\n",
    "fig_conf = figure(tools=\"\",\n",
    "                  y_axis_label = 'Predicted model',\n",
    "                  x_axis_label = r'True model',\n",
    "                  y_range=sorted(processes, reverse=True),\n",
    "                  x_range=processes,\n",
    "                 plot_height = size_t2, plot_width = size_t2,\n",
    "                 margin = (0,20,0,20))\n",
    "fig_conf.background_fill_color=None\n",
    "\n",
    "fig_roc = figure(x_axis_label = 'False Positive Rate', y_axis_label = 'True Positive Rate', plot_height = int(size_t2/1.5), plot_width = size_t2, margin = (0,20,0,20))   \n",
    "fig_roc.background_fill_color=None\n",
    "\n",
    "# Updates\n",
    "update_t2()\n",
    "\n",
    "def update_select_team_t2(attrname, old, new):\n",
    "    teams_t2 = [s.split('_')[0] for s in df_t2[dims.index(dim_select_t2.value)].keys()[6:].tolist()][0:-1:6]\n",
    "    team_select_t2.options = teams_t2  \n",
    "    team_select_t2.value = team_select_t2.options[0]\n",
    "    \n",
    "    noise_group_t2.options = ['All']+[str(n) for n in np.unique(df_t2[dims.index(dim_select_t2.value)].loc_error)[::-1]]\n",
    "    noise_group_t2.value = 'All'\n",
    "    \n",
    "    update_t2()    \n",
    "\n",
    "controls_t2 = [dim_select_t2, team_select_t2, noise_group_t2]\n",
    "for control in controls_t2:\n",
    "    control.on_change('value', lambda attr, old, new: update_t2())\n",
    "sliders_t2 = [alpha_slider_t2, length_slider_t2]\n",
    "for control in sliders_t2:\n",
    "    control.on_change('value_throttled', lambda attr, old, new: update_t2())\n",
    "all_controls_t2 = controls_t2+sliders_t2\n",
    "\n",
    "dim_select_t2.on_change('value', update_select_team_t2)\n",
    "\n",
    "# Layout\n",
    "inputs_t2 = column(*all_controls_t2+[div_t2_aux], width = 220, height = 500)\n",
    "\n",
    "l2 = grid([div_t2,\n",
    "           row(inputs_t2, fig_conf, fig_roc)])\n",
    "\n",
    "\n",
    "if notebook:\n",
    "    def modify_doc(doc):\n",
    "        doc.add_root(row(l2, width=10))\n",
    "\n",
    "    handler = FunctionHandler(modify_doc)\n",
    "    app = Application(handler)\n",
    "    show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_data(attr, old, new):   \n",
    "    \n",
    "    # Get data\n",
    "    decoded = b64decode(new)    \n",
    "    f = io.BytesIO(decoded) \n",
    "    \n",
    "    correct_dim_t1, correct_dim_t2, correct_dim_t3 = [], [], []\n",
    "    \n",
    "    if file_input.filename[-5] == '1':        \n",
    "        correct_dim_t1 = upload_t1(f)        \n",
    "    if file_input.filename[-5] == '2':        \n",
    "        correct_dim_t2 = upload_t2(f)\n",
    "    if file_input.filename[-5] == '3':        \n",
    "        correct_dim_t3 = upload_t3(f)     \n",
    "    \n",
    "    # Text\n",
    "    div_upload_aux.text = f\"\"\" <b>You have correctly participated in: </b>     \n",
    "    <br>\n",
    "    T1 - Dim = {correct_dim_t1}\n",
    "    <br>\n",
    "    T2 - Dim = {correct_dim_t2}\n",
    "    <br>\n",
    "    T3 - Dim = {correct_dim_t3}\"\"\"\n",
    "    \n",
    "    # Update main figure\n",
    "    if file_input.filename[-5] == '1' or file_input.filename[-5] == '2':\n",
    "        update_main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_summary_t1(dim):\n",
    "\n",
    "    lengths = np.arange(10,1020,50)\n",
    "    alphas = np.arange(0.05, 2.1, 0.2)\n",
    "    noise = [0.1, 0.5, 1]\n",
    "    new_column = []\n",
    "    for idxl, l in enumerate((lengths[:-1])):\n",
    "        for idxa, a in enumerate(alphas[:-1]):\n",
    "            for idx_m, m in enumerate(processes):\n",
    "                for n in noise:  \n",
    "\n",
    "                    preds = df_t1[dim-1][\n",
    "                                    (df_t1[dim-1].model == processes.index(m)) &\n",
    "                                    (df_t1[dim-1].alpha >= alphas[idxa]) &\n",
    "                                    (df_t1[dim-1].alpha < alphas[idxa+1]) &\n",
    "                                    (df_t1[dim-1].length >= lengths[idxl]) &\n",
    "                                    (df_t1[dim-1].length < lengths[idxl+1]) &\n",
    "                                    (df_t1[dim-1].loc_error == n)]\n",
    "                    preds = preds['upload']\n",
    "                    if len(preds) > 0:\n",
    "                        trues = df_t1[dim-1]['alpha'][preds.index]\n",
    "                        mae = (preds-trues).abs().mean()\n",
    "                        new_column.append(mae)\n",
    "                    \n",
    "    df_t1_results[dim-1]['upload'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_summary_t2(dim):\n",
    "\n",
    "    lengths = np.arange(10,1020,50)\n",
    "    alphas = np.arange(0.05, 2.1, 0.2)\n",
    "    noise = [0.1, 0.5, 1]\n",
    "    new_column = []\n",
    "    for idxl, l in enumerate((lengths[:-1])):\n",
    "        for idxa, a in enumerate(alphas[:-1]):\n",
    "                for n in noise:  \n",
    "\n",
    "                    preds = df_t2[dim-1][\n",
    "                                    (df_t2[dim-1].alpha >= alphas[idxa]) &\n",
    "                                    (df_t2[dim-1].alpha < alphas[idxa+1]) &\n",
    "                                    (df_t2[dim-1].length >= lengths[idxl]) &\n",
    "                                    (df_t2[dim-1].length < lengths[idxl+1]) &\n",
    "                                    (df_t2[dim-1].loc_error == n)]\n",
    "                    preds = preds['upload']\n",
    "                    if len(preds) > 0:\n",
    "                        trues = df_t2[dim-1]['model'][preds.index]\n",
    "                        f1 = f1_score(trues, preds, average = 'micro')\n",
    "                        new_column.append(f1)\n",
    "                    \n",
    "    df_t2_results[dim-1]['upload'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_t1(f):\n",
    "    \n",
    "    df = pd.read_csv(f, header = None, sep = ';')    \n",
    "    df.columns = ['dim', 'preds']\n",
    "    \n",
    "    correct_dim_t1 = []\n",
    "    for dim in [1,2,3]:            \n",
    "        # Read data and update main dataframe\n",
    "        df_dim = df.loc[lambda df: (df['dim'] == dim)]   \n",
    "        \n",
    "        # If there are no prediction for this dimension\n",
    "        if df_dim.shape[0] == 0: continue\n",
    "\n",
    "        if len(df_dim) != 10000:          \n",
    "            df_dim = df_dim.head(10000)  \n",
    "            \n",
    "        df_t1[dim-1]['upload'] = df_dim['preds'].values   \n",
    "        # Saving dimensions participated\n",
    "        correct_dim_t1.append(dim)\n",
    "        \n",
    "        # Update summary tab information\n",
    "        upload_summary_t1(dim)\n",
    "        \n",
    "    # Add upload to controls    \n",
    "    team_select_t1.options = df_t1[dims.index(dim_select_t1.value)].keys()[6:].tolist()  \n",
    "    team_select_t1.value = team_select_t1.options[-1]\n",
    "    \n",
    "    return correct_dim_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_t2(f):\n",
    "    \n",
    "    df = pd.read_csv(f, header = None, sep = ';') \n",
    "    df.columns = ['dim']+list(range(5))\n",
    "    \n",
    "    correct_dim_t2 = []\n",
    "    for dim in [1,2,3]:            \n",
    "        # Read data and update main dataframe\n",
    "        df_dim = df.loc[lambda df: (df['dim'] == dim)]  \n",
    "        \n",
    "        # If there are no prediction for this dimension\n",
    "        if df_dim.shape[0] == 0: continue\n",
    "\n",
    "        if len(df_dim) != 10000:          \n",
    "            df_dim = df_dim.head(10000)   \n",
    "\n",
    "        df_t2[dim-1]['upload'] = df_dim[list(range(5))].idxmax(axis = 'columns').values\n",
    "\n",
    "        for i in range(5):\n",
    "            df_t2[dim-1]['upload_'+processes_simp[i]] = df_dim[i].values\n",
    "        \n",
    "        # Saving dimensions participated\n",
    "        correct_dim_t2.append(dim)\n",
    "        \n",
    "        # Update summary tab information\n",
    "        upload_summary_t2(dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Add upload to controls  \n",
    "    teams_t2 = [s.split('_')[0] for s in df_t2[dims.index(dim_select_t2.value)].keys()[6:].tolist()][0:-1:6]\n",
    "    team_select_t2.options = teams_t2  \n",
    "    team_select_t2.value = team_select_t2.options[-1]\n",
    "    \n",
    "    return correct_dim_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def upload_t3(f):\n",
    "    \n",
    "    df = pd.read_csv(f, header = None, sep = ';') \n",
    "    df.columns = ['dim']+list(range(5))\n",
    "    \n",
    "    labels_t3 = ['cp', 'm1', 'a1', 'm2', 'a2']\n",
    "    correct_dim_t3 = []\n",
    "    for dim in [1,2,3]:            \n",
    "        # Read data and update main dataframe\n",
    "        df_dim = df.loc[lambda df: (df['dim'] == dim)]     \n",
    "\n",
    "        # If there are no prediction for this dimension\n",
    "        if df_dim.shape[0] == 0: continue\n",
    "\n",
    "        if len(df_dim) != 10000:          \n",
    "            df_dim = df_dim.head(10000)          \n",
    "\n",
    "        for idx_l, label in enumerate(labels_t3):   \n",
    "            df_t3[dim-1]['upload_'+label] = df_dim[idx_l].values\n",
    "\n",
    "        # Saving dimensions participated\n",
    "        correct_dim_t3.append(dim)\n",
    "        \n",
    "    # Add upload to controls\n",
    "    team_select_t3.options = np.unique([n[:-3] for n in df_t3[dims.index(dim_select_t3.value)].keys()[6:]]).tolist()\n",
    "    team_select_t3.value = team_select_t3.options[-1]\n",
    "\n",
    "    return correct_dim_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "# Widgets\n",
    "file_input = FileInput(accept=\".txt\")\n",
    "file_input.on_change('value', upload_data)\n",
    "\n",
    "# Divs\n",
    "div_upload = Div(text= f\"\"\" <h2>New submission</h2>\n",
    "\n",
    "<p align = \"justify\"> Score the performance of your method for the characterization of anomalous diffusion and compare it with other participants. \n",
    "<br>\n",
    "<br>\n",
    "Run your code to obtain predictions for the \n",
    "<a href=\"https://drive.google.com/drive/folders/1h2cg1RNoKbhTiiPSNCHyav2NaRA6TGdR?usp=sharing\" target=\"_blank\"> AnDI test dataset</a>.\n",
    "Upload the results using the button below. \n",
    "Uploaded files must follow the same syntax as for the AnDi Challenge, as described \n",
    "<a href=\"https://competitions.codalab.org/competitions/23601#learn_the_details-instructions\" target=\"_blank\"> here</a>. \n",
    "Files must be named 'task1.txt', 'task2.txt', or 'task3.txt', according to the task you are participating in. \n",
    "Each task requires a separate upload. \n",
    "<br>\n",
    "<br>\n",
    "The tool will output a summary of your upload, printing the dimensions for which you successfully participated. \n",
    "The results of your submissions will be shown in the tab of the corresponding task, tagged as 'upload'.</p>\n",
    "\n",
    "\"\"\", width = 500, margin = (0,0,20,0))\n",
    "\n",
    "div_upload_aux = Div(text= \"\" , width = 100)\n",
    "\n",
    "# div_mail = Div(text= f\"\"\" <h2>Send us a mail!</h2>\n",
    "\n",
    "# low the same sintaxis as for the AnDi Challenge. You can check the details <a href='https://competitions.codalab.org/competitions/23601#learn_the_details-instructions'>here</a>. \n",
    "# Remember, the files' name should be 'task1.tasdas.\"\"\")\n",
    "\n",
    "lnew = grid([ \n",
    "            div_upload,\n",
    "            file_input,\n",
    "            div_upload_aux])\n",
    "\n",
    "if notebook:\n",
    "    def modify_doc(doc):\n",
    "        doc.add_root(row(lnew, width=10))\n",
    "\n",
    "    handler = FunctionHandler(modify_doc)\n",
    "    app = Application(handler)\n",
    "    show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 vs T2 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def weighted(cols, weights): \n",
    "    return np.average(cols, weights=weights, axis = 0)\n",
    "\n",
    "def update_main():\n",
    "    \n",
    "    # Updating data\n",
    "    df_dim_t1 = df_t1_results[dims.index(dim_select_main.value)]\n",
    "    df_dim_t2 = df_t2_results[dims.index(dim_select_main.value)]\n",
    "    \n",
    "    df_dim_t1 = df_dim_t1[(df_dim_t1.alpha >= round(alpha_slider_main.value[0],2)) &\n",
    "                            (df_dim_t1.alpha <= alpha_slider_main.value[1]) &\n",
    "                            (df_dim_t1.length >= length_slider_main.value[0]) &\n",
    "                            (df_dim_t1.length <= length_slider_main.value[1]) ]\n",
    "\n",
    "    df_dim_t2 = df_dim_t2[(df_dim_t2.alpha >= round(alpha_slider_main.value[0], 2)) &\n",
    "                            (df_dim_t2.alpha <= alpha_slider_main.value[1]) &\n",
    "                            (df_dim_t2.length >= length_slider_main.value[0]) &\n",
    "                            (df_dim_t2.length <= length_slider_main.value[1]) ]\n",
    "    \n",
    "    \n",
    "\n",
    "    if model_group_main.value != 'All':\n",
    "        df_dim_t1 = df_dim_t1[df_dim_t1.model == model_group_main.value]\n",
    "    if noise_group_main.value != 'All':\n",
    "        df_dim_t1 = df_dim_t1[df_dim_t1.loc_error == float(noise_group_main.value)]\n",
    "        df_dim_t2 = df_dim_t2[df_dim_t2.loc_error == float(noise_group_main.value)]\n",
    "    \n",
    "    # Weighted average\n",
    "    weig_p1 = partial(weighted, weights = df_dim_t1['num_traj'])\n",
    "    update_t1 = df_dim_t1[df_dim_t1.columns[6:]].apply(weig_p1)\n",
    "    \n",
    "    weig_p2 = partial(weighted, weights = df_dim_t2['num_traj'])\n",
    "    update_t2 = df_dim_t2[df_dim_t2.columns[6:]].apply(weig_p2)\n",
    "\n",
    "    team_list = set(update_t1.keys().tolist())\n",
    "    team_list.update(update_t2.keys().tolist())\n",
    "    team_list = list(team_list)\n",
    "\n",
    "\n",
    "    mae, f1 = [], []\n",
    "    mae_tooltip, f1_tooltip = [], []\n",
    "    for team in team_list:\n",
    "        try: \n",
    "            mae.append(update_t1[team])\n",
    "            mae_tooltip.append(update_t1[team])\n",
    "        except: \n",
    "            mae.append(mae_not)\n",
    "            mae_tooltip.append(' -')\n",
    "\n",
    "        try:\n",
    "            f1.append(update_t2[team])\n",
    "            f1_tooltip.append(update_t2[team])\n",
    "        except: \n",
    "            f1.append(f1_not)\n",
    "            f1_tooltip.append(' -')       \n",
    "        \n",
    "\n",
    "    d = pd.DataFrame(data = [[t, m, f, mtt, ftt] for t, m, f, mtt, ftt in zip(team_list, mae, f1, mae_tooltip, f1_tooltip)], \n",
    "                     columns = ['team', 'mae', 'f1score', 'mae_tt', 'f1_tt'])\n",
    "    d['index'] = d.index     \n",
    "    \n",
    "    # If there are no enough trajectories\n",
    "    if df_dim_t1['num_traj'].sum() == 0 or df_dim_t2['num_traj'].sum() == 0:\n",
    "        div_main_aux.text = f\"\"\"\n",
    "        <p style=\"color:red\">  <b>Warning!</b> <br> Not enough trajectories. Select wider option ranges.</p>\"\"\"\n",
    "        return\n",
    "    \n",
    "    d.sort_values(by=['mae'], inplace=True)\n",
    "    d_t1 = d[d['mae'] != mae_not]\n",
    "\n",
    "    d.sort_values(by=['f1score'], inplace=True)\n",
    "    d_t2 = d[d['f1score'] != f1_not]\n",
    "    \n",
    "    \n",
    "    source  = ColumnDataSource(d) \n",
    "    source_t1  = ColumnDataSource(d_t1)\n",
    "    source_t2  = ColumnDataSource(d_t2)\n",
    "    \n",
    "    # Figure\n",
    "    mapper = LinearColorMapper(palette = \"Turbo256\", low = 0, high = len(team_list))   \n",
    "    fig_main.renderers = []\n",
    "    fig_main.circle(x=\"mae\", y=\"f1score\", source=source, size=10, \n",
    "                    line_color='black', fill_color = {\"field\": 'index', \"transform\": mapper}, fill_alpha = 0.6)\n",
    "    fig_main.tools[-1] = HoverTool(tooltips=TOOLTIPS)\n",
    "    \n",
    "    fig_mae.renderers = []    \n",
    "    fig_mae.x_range.factors = []\n",
    "    fig_mae.x_range.factors = d_t1['team'].tolist()\n",
    "    fig_mae.circle(x='team', y = 'mae', size = 10, source = source_t1,  \n",
    "                        line_color='black', fill_color = {\"field\": 'index', \"transform\": mapper}, fill_alpha = 0.6)\n",
    "    \n",
    "    fig_f1.renderers = []\n",
    "    fig_f1.y_range.factors = []\n",
    "    fig_f1.y_range.factors = d_t2['team'].tolist()    \n",
    "    fig_f1.circle(y='team', x = 'f1score', size = 10, source = source_t2,  \n",
    "                        line_color='black', fill_color = {\"field\": 'index', \"transform\": mapper}, fill_alpha = 0.6)\n",
    "    \n",
    "    \n",
    "    # Text\n",
    "    div_main_aux.text = f\"\"\"\n",
    "    <b>Number of trajectories:</b>\n",
    "    <br>\n",
    "    Task 1 = {df_dim_t1['num_traj'].sum()}\n",
    "    <br>\n",
    "    Task 2 = {df_dim_t2['num_traj'].sum()}\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "# If there is a change in dimensions, first change the noise options then \n",
    "# go for usual update\n",
    "def update_dim():\n",
    "    noise_group_main.options = ['All']+[str(n) for n in np.unique(df_t1_results[dims.index(dim_select_main.value)].loc_error)[::-1]]\n",
    "    noise_group_main.value = 'All'\n",
    "    \n",
    "    update_main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "lengths = np.arange(10,1000,1)\n",
    "alphas = np.arange(0.05, 2.1, 0.2)\n",
    "noise = [0.1, 0.5, 1]\n",
    "\n",
    "mae_not = 0.6; f1_not = 0.3\n",
    "\n",
    "dim_select_main = Select(title=\"Dimensions\", value=\"1D\", options=dims)\n",
    "\n",
    "alpha_slider_main = RangeSlider(start=alphas[0], end=2, value=(alphas[0], 2), step=alphas[1]-alphas[0],  title=r\"Anomalous exponent\")\n",
    "\n",
    "length_slider_main = RangeSlider(start=lengths[0], end=1000, value=(lengths[0], 1000), step=lengths[1]-lengths[0], title=r\"Length\")\n",
    "\n",
    "model_group_main = Select(options=['All']+[p for p in processes], value=\"All\", title ='Diffusion model')\n",
    "noise_group_main = Select(options=['All']+[str(n) for n in np.unique(df_t1_results[0].loc_error)[::-1]], value=\"All\", title ='Signal to Noise ratio (SNR)')\n",
    "\n",
    "\n",
    "# Figure\n",
    "TOOLTIPS=[\n",
    "    (\"Team\", \"@team\"),\n",
    "    (\"MAE\", \"@mae_tt\"),\n",
    "    (\"F1 score\", \"@f1_tt\")\n",
    "]\n",
    "\n",
    "fig_main = figure(x_range = [0.025,0.62], y_range = [0.25,1.025], tools= \"pan,wheel_zoom,reset,box_zoom\", \n",
    "                  x_axis_label = 'MAE', y_axis_label = 'F1 score', margin = (0,0,0,20))\n",
    "fig_main.background_fill_color=None\n",
    "\n",
    "hover = HoverTool(tooltips=TOOLTIPS)\n",
    "fig_main.add_tools(hover)\n",
    "\n",
    "glyph_t1 = Label(x=0.42, y=0.3, text=\"Task 1 not submitted\", text_color = '#949494')\n",
    "glyph_t2 = Label(x=0.6, y=0.85, text=\"Task 2 not submitted\", text_color = '#949494', angle = 90, angle_units = 'deg')\n",
    "hline = Span(location=mae_not, dimension='height', line_color='#C5C5C5', line_dash='dashed', line_width=3, level = 'underlay')\n",
    "vline = Span(location=f1_not, dimension='width', line_color='#C5C5C5', line_dash='dashed', line_width=3, level = 'underlay')\n",
    "for x in [glyph_t1, glyph_t2, hline, vline]:\n",
    "    fig_main.add_layout(x)\n",
    "    \n",
    "# Horizontal and vertical figures\n",
    "fig_mae = figure(x_range=[''], plot_width = fig_main.plot_width, plot_height = 200, y_axis_label = 'MAE', y_range = [-0.1,0.6], margin = (0,0,0,20), tools = '')\n",
    "fig_mae.yaxis.ticker = np.arange(0,0.61,0.1)\n",
    "fig_mae.xaxis.major_label_orientation = np.pi/4\n",
    "\n",
    "fig_f1 = figure(y_range=[''], plot_height = fig_main.plot_height, plot_width = 250, x_axis_label = 'F1 score', x_range = [0.15, 1.2], y_axis_location=\"right\", tools = '')\n",
    "fig_f1.xaxis.ticker = [0.25, 0.5, 0.75, 1]\n",
    " \n",
    "\n",
    "# Heading\n",
    "# <a href=\"https://doi.org/10.1117/12.2567914\"><img src=\"http://andi-challenge.org/wp-content/uploads/2021/02/banner_challenge_noborder.png\" width=\"1000\", height =\"178.328\"  ></a>\n",
    "div = Div(text= \"\"\"\n",
    "<br>\n",
    "<h1>AnDi Challenge interactive tool</h1>\n",
    "\n",
    "Explore the results of the AnDi challenge interactively. Here you will find access to the details of each submissions results over the different features of the dataset. \n",
    "This tab showcases a summary of the results of Task 1 and Task 2. The rest of the tabs corresponds to each of the tasks separatedely.\"\"\", \n",
    "          width = 1000, margin = (0,0,20,0))\n",
    "\n",
    "\n",
    "div_main_aux = Div(text= \"\" , width = 220)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Updates\n",
    "update_main() \n",
    "controls = [dim_select_main, model_group_main, noise_group_main]\n",
    "for control in controls:\n",
    "    if control == dim_select_main:\n",
    "        control.on_change('value', lambda attr, old, new: update_dim())\n",
    "    else:\n",
    "        control.on_change('value', lambda attr, old, new: update_main())\n",
    "sliders = [alpha_slider_main, length_slider_main]\n",
    "for control in sliders:\n",
    "    control.on_change('value_throttled', lambda attr, old, new: update_main())\n",
    "all_controls = controls+sliders\n",
    "\n",
    "# Layout\n",
    "inputs = column(*all_controls+[div_main_aux], width = 200, height = 500)\n",
    "layout_main = row(inputs, gridplot([[fig_main, fig_f1], [fig_mae, None]], merge_tools=False))\n",
    "layout_main = column(div, layout_main)\n",
    "\n",
    "if notebook:\n",
    "    def modify_doc(doc):\n",
    "        doc.add_root(row(layout_main, width=3))\n",
    "\n",
    "    handler = FunctionHandler(modify_doc)\n",
    "    app = Application(handler)\n",
    "    show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def updated_preds_t3(df, team, \n",
    "                     model1 = None, model2 = None,\n",
    "                     a1_min = 0, a1_max = 2, \n",
    "                     a2_min = 0, a2_max = 2,\n",
    "                     cp_min = 1, cp_max = 199):\n",
    "    # Exponent 1\n",
    "    df = df.loc[lambda df: (df['alpha1'] >= a1_min) & (df['alpha1'] <= a1_max)]\n",
    "    # Exponent 2\n",
    "    df = df.loc[lambda df: (df['alpha2'] >= a2_min) & (df['alpha2'] <= a2_max)]\n",
    "    # Model 1\n",
    "    if model1 != 'All' and model1 != None:\n",
    "        model = processes.index(model1)\n",
    "        df = df.loc[lambda df: (df['model1'] == model)]\n",
    "    if model2 != 'All' and model2 != None:\n",
    "        model = processes.index(model2)\n",
    "        df = df.loc[lambda df: (df['model2'] == model)]\n",
    "    # Change point\n",
    "    df = df.loc[lambda df: (df['change_point'] >= cp_min) & (df['change_point'] <= cp_max)]\n",
    "    \n",
    "    filter_col = [col for col in df if col.startswith(team)]\n",
    "    \n",
    "    return df[filter_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def rmse_mod(p):\n",
    "    \n",
    "    kwargs = {'df': df_t3[dims.index(dim_select_t3.value)], \n",
    "              'a1_min': alpha1_slider_t3.value[0], 'a1_max': alpha1_slider_t3.value[1],\n",
    "              'a2_min': alpha2_slider_t3.value[0], 'a2_max': alpha2_slider_t3.value[1],\n",
    "              'cp_min': cp_slider_t3.value[0], 'cp_max': cp_slider_t3.value[1],\n",
    "              'team': team_select_t3.value}\n",
    "\n",
    "\n",
    "\n",
    "    model1, model2, rmse, color, posx, posy, text = [], [], [], [], [], [], []\n",
    "\n",
    "    for idx1, m1 in enumerate(processes):\n",
    "        for idx2, m2 in enumerate(processes):\n",
    "            model1.append(m1)\n",
    "            model2.append(m2)\n",
    "\n",
    "            df = updated_preds_t3(model1 = m1, model2 = m2, **kwargs)\n",
    "\n",
    "            preds = df[df.columns[0]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['change_point'][preds.index].values\n",
    "            \n",
    "            if len(trues) > 0:\n",
    "                rmse.append(np.sqrt(((preds.values-trues)**2).mean()))          \n",
    "                text.append(str(round(rmse[-1],2)))\n",
    "            else:\n",
    "                rmse.append(0)          \n",
    "                text.append('  --')\n",
    "                \n",
    "            color.append('#FF5733')\n",
    "            posx.append(idx1+0.3)\n",
    "            posy.append(4-idx2+0.4)\n",
    "\n",
    "    rmse = np.array(rmse)\n",
    "    alpha = (rmse-np.min(rmse[rmse > 0]))/(np.max(rmse)-np.min(rmse[rmse > 0]))+0.1\n",
    "\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(model1 = model1, model2 = model2, colors = color, alphas = alpha, posx = posx, posy = posy, text = text)\n",
    "    )\n",
    "\n",
    "    p.renderers = []\n",
    "    rectwidth = 0.9\n",
    "    p.rect('model1', 'model2', rectwidth, rectwidth, source=source,\n",
    "          color='colors', alpha='alphas',line_width=1)\n",
    "    glyph = Text(x=\"posx\", y=\"posy\", text=\"text\", text_color = '#000000')\n",
    "    p.add_glyph(source, glyph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def rmse_alpha(p):\n",
    "    \n",
    "    kwargs = {'df': df_t3[dims.index(dim_select_t3.value)], \n",
    "              'model1': model1_group_t3.value, 'model2': model2_group_t3.value,\n",
    "              'cp_min': cp_slider_t3.value[0], 'cp_max': cp_slider_t3.value[1],\n",
    "              'team': team_select_t3.value}\n",
    "\n",
    "\n",
    "    alpha1, alpha2, rmse, color, posx, posy, text = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "    for idx1, a_1 in enumerate(alphas_range[:-1]):\n",
    "        for idx2, a_2 in enumerate(alphas_range[:-1]):\n",
    "            alpha1.append(idx1+0.5)\n",
    "            alpha2.append(idx2+0.5)           \n",
    "\n",
    "            df = updated_preds_t3(a1_min = a_1, a1_max = a_1+0.5,\n",
    "                                  a2_min = a_2, a2_max = a_2+0.5,\n",
    "                                  **kwargs)\n",
    "\n",
    "            preds = df[df.columns[0]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['change_point'][preds.index].values\n",
    "\n",
    "            if len(trues) > 0:\n",
    "                rmse.append(np.sqrt(((preds.values-trues)**2).mean()))          \n",
    "                text.append(str(round(rmse[-1],2)))\n",
    "            else:\n",
    "                rmse.append(0)          \n",
    "                text.append('--')\n",
    "\n",
    "            color.append('#FF5733')\n",
    "            posx.append(idx1+0.35)\n",
    "            posy.append(idx2+0.4)\n",
    "\n",
    "    rmse = np.array(rmse)\n",
    "\n",
    "    alpha = (rmse-np.min(rmse[rmse > 0]))/(np.max(rmse)-np.min(rmse[rmse > 0]))+0.1\n",
    "\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(alpha1 = alpha1, alpha2 = alpha2, colors = color, alphas = alpha, posx = posx, posy = posy, text = text)\n",
    "    )\n",
    "    \n",
    "    p.renderers = []\n",
    "    rectwidth = 0.9\n",
    "    p.rect('alpha1', 'alpha2', rectwidth, rectwidth, source=source,\n",
    "          color='colors', alpha='alphas',line_width=1)\n",
    "    glyph = Text(x=\"posx\", y=\"posy\", text=\"text\", text_color = '#000000')\n",
    "    p.add_glyph(source, glyph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def cp_figures(rmse, mae, f1):\n",
    "    \n",
    "    kwargs = {'df': df_t3[dims.index(dim_select_t3.value)], \n",
    "                  'model1': model1_group_t3.value, 'model2': model2_group_t3.value,\n",
    "                  'a1_min': alpha1_slider_t3.value[0], 'a1_max': alpha1_slider_t3.value[1],\n",
    "                  'a2_min': alpha2_slider_t3.value[0], 'a2_max': alpha2_slider_t3.value[1],\n",
    "                  'team': team_select_t3.value}\n",
    "\n",
    "    \n",
    "    rmse_cp, f1_s1, f1_s2, mae_s1, mae_s2 = [], [], [], [], []\n",
    "    for idx, cp in enumerate(cut_avg[:-1]):\n",
    "\n",
    "\n",
    "            df = updated_preds_t3(cp_min = cp, cp_max = cp+20,\n",
    "                                  **kwargs)\n",
    "            \n",
    "            # If there are no enough trajectories\n",
    "            if df.shape[0] == 0:\n",
    "                div_t3_aux.text = f\"\"\"\n",
    "                <p style=\"color:red\">  <b>Warning!</b> <br> Not enough trajectories for some analysis. Select wider option ranges.</p>\"\"\"\n",
    "                return\n",
    "            \n",
    "            # rmse\n",
    "            preds = df[df.columns[0]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['change_point'][preds.index].values\n",
    "            rmse_cp.append(np.sqrt(((preds.values-trues)**2).mean()))\n",
    "\n",
    "            # f1 s1\n",
    "            preds = df[df.columns[1]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['model1'][preds.index].values\n",
    "            f1_s1.append(f1_score(trues, preds, average = 'micro'))\n",
    "\n",
    "            # f1 s2\n",
    "            preds = df[df.columns[3]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['model2'][preds.index].values\n",
    "            f1_s2.append(f1_score(trues, preds, average = 'micro'))\n",
    "\n",
    "            # mae s1\n",
    "            preds = df[df.columns[2]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['alpha1'][preds.index].values\n",
    "            mae_s1.append((preds-trues).abs().mean())\n",
    "\n",
    "            # mae s1\n",
    "            preds = df[df.columns[4]]\n",
    "            trues = df_t3[dims.index(dim_select_t3.value)]['alpha2'][preds.index].values\n",
    "            mae_s2.append((preds-trues).abs().mean())\n",
    "\n",
    "    rmse.renderers = []\n",
    "    rmse.line(xticks, rmse_cp, line_width = 2, line_color = '#FF5733')\n",
    "    rmse.circle(xticks, rmse_cp, line_color = '#FF5733', fill_color=\"white\", size=8)\n",
    "\n",
    "    f1.renderers = []\n",
    "    l1 = f1.line(xticks, f1_s1, line_width = 2, line_color = '#36B33F')\n",
    "    l2 = f1.line(xticks, f1_s2, line_width = 2, line_color = '#1294B3')\n",
    "    f1.circle(xticks, f1_s1, line_width = 2, line_color = '#36B33F', fill_color=\"white\", size=8)\n",
    "    f1.circle(xticks, f1_s2, line_width = 2, line_color = '#1294B3', fill_color=\"white\", size=8)\n",
    "    \n",
    "    mae.renderers = []\n",
    "    mae.line(xticks, mae_s1, line_width = 2, line_color = '#36B33F')\n",
    "    mae.line(xticks, mae_s2, line_width = 2, line_color = '#1294B3')\n",
    "    mae.circle(xticks, mae_s1, line_width = 2, line_color = '#36B33F', fill_color=\"white\", size=8)\n",
    "    mae.circle(xticks, mae_s2, line_width = 2, line_color = '#1294B3', fill_color=\"white\", size=8)\n",
    "    \n",
    "    \n",
    "    df = updated_preds_t3(**kwargs)\n",
    "    div_t3_aux.text = f\"\"\" <b>Prediction summary </b>\n",
    "    <br>\n",
    "    Number trajs. = {round(df.shape[0],3)}\n",
    "    <br>\n",
    "    RMSE = {round(np.mean(rmse_cp),3)} \n",
    "    <br>\n",
    "    MAE = {round(np.mean(mae_s1+mae_s2),3)}\n",
    "    <br>\n",
    "    F1-score = {round(np.mean(f1_s1+f1_s2),3)}\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#| hide\n",
    "\n",
    "def update_t3():\n",
    "        rmse_mod(fig_rmse_mod_t3)\n",
    "        rmse_alpha(fig_rmse_alpha_t3)\n",
    "        cp_figures(fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3)\n",
    "        \n",
    "        \n",
    "def update_t3_mod():   \n",
    "        rmse_alpha(fig_rmse_alpha_t3)\n",
    "        cp_figures(fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3)\n",
    "        \n",
    "def update_t3_alpha():     \n",
    "        rmse_mod(fig_rmse_mod_t3)\n",
    "        cp_figures(fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "# Widgets\n",
    "dim_select_t3 = Select(value=\"1D\", options=dims, title = 'Dimension')\n",
    "team_select_t3 = Select(value=np.unique([n[:-3] for n in df_t3[0].keys()[6:]])[0], options = np.unique([n[:-3] for n in df_t3[0].keys()[6:]]).tolist(), title = 'Team')\n",
    "\n",
    "alpha1_slider_t3 = RangeSlider(start=0, end=2, value=(0, 2), step=.05, title=r\"Exponent segment 1\")\n",
    "alpha2_slider_t3 = RangeSlider(start=0, end=2, value=(0, 2), step=.05, title=r\"Exponent segment 2\")\n",
    "\n",
    "\n",
    "model1_group_t3 = Select(options=['All']+[p for p in processes], value=\"All\", title ='Model segment 1')\n",
    "model2_group_t3 = Select(options=['All']+[p for p in processes], value=\"All\", title ='Model segment 2')\n",
    "cp_slider_t3 = RangeSlider(start=1, end=199, value=(0, 199), step=1, title=r\"Changepoint\")\n",
    "\n",
    "\n",
    "\n",
    "# Text    \n",
    "div_t3 = Div(text= f\"\"\" <h2>Task 3 - Segmentation of trajectories</h2>\n",
    "The goal of this task is to find the changepoint in which a trajectory changes either its anomalous diffusion exponent or its diffusion model. \n",
    "Participants have to predict the changepoint position and the anomalous diffusion exponent and diffusion model of the two resulting segments.\n",
    "The upper-central figure shows the RMSE in the changepoint w.r.t. to the diffusion models of the first and second segment.\n",
    "The lower-central figure shows the same RMSE but w.r.t. to the anomalous diffusion exponent of the first and second segment.\n",
    "The three rightmost figures show the RMSE, the MAE on the exponent prediction and the F1-score of the model classification, all as a function of the changepoint.\n",
    "\"\"\", width = 1000, margin = (0,0,20,0))\n",
    "\n",
    "div_t3_aux = Div(text= \"\" , width = 220)\n",
    "\n",
    "# Plots\n",
    "mod_alpha_width = 500\n",
    "fig_rmse_mod_t3 = figure(tools=\"\",  \n",
    "                         y_range=sorted(processes, reverse=True), \n",
    "                         x_range=processes, x_axis_label = 'Model first segment', y_axis_label = 'Model second segment',\n",
    "                         plot_width = mod_alpha_width,\n",
    "                        plot_height = mod_alpha_width, \n",
    "                        margin = (0,20,0,20))\n",
    "fig_rmse_mod_t3.background_fill_color=None\n",
    "rmse_mod(fig_rmse_mod_t3)\n",
    "\n",
    "\n",
    "    \n",
    "alphas_range = [0.05,0.5,1,1.5,2]   \n",
    "fig_rmse_alpha_t3 = figure(tools=\"\",\n",
    "                      y_range = [f'{round(alphas_range[idx],2)}-{round(alphas_range[idx+1],2)}' for idx, _ in enumerate(alphas_range[:-1])],\n",
    "                      x_range = [f'{round(alphas_range[idx],2)}-{round(alphas_range[idx+1],2)}' for idx, _ in enumerate(alphas_range[:-1])],\n",
    "                      x_axis_label = 'Exponent first segment', y_axis_label = 'Exponent second segment',\n",
    "                      plot_width = mod_alpha_width,\n",
    "                      plot_height = mod_alpha_width,\n",
    "                      margin = (0,20,0,20))\n",
    "fig_rmse_alpha_t3.background_fill_color=None\n",
    "rmse_alpha(fig_rmse_alpha_t3)\n",
    "\n",
    "\n",
    "cut_avg = np.arange(10, 201, 20)\n",
    "cp_width = 400\n",
    "xticks = [f'{i}-{i+20}' for i in cut_avg[:-1]]\n",
    "fig_rmse_cp_t3 = figure(tools=\"\",\n",
    "                        plot_width=cp_width, plot_height = int(0.8*cp_width), \n",
    "                        x_range = xticks, x_axis_label = 'Changepoint',\n",
    "                        y_axis_label = 'RMSE changepoint',\n",
    "                        margin = (20,0,0,0))\n",
    "fig_f1_cp_t3 = figure(tools=\"\",\n",
    "                      plot_width=cp_width, plot_height = int(0.8*cp_width), \n",
    "                      x_range = xticks, x_axis_label = 'Changepoint', \n",
    "                      y_axis_label = 'F1-score diffusion model',\n",
    "                      margin = (20,0,0,0))\n",
    "fig_mae_cp_t3 = figure(tools=\"\",\n",
    "                       plot_width=cp_width, plot_height = int(0.8*cp_width),\n",
    "                       x_range = xticks, x_axis_label = 'Changepoint',\n",
    "                       y_axis_label = 'MAE anomalous exponent',\n",
    "                       margin = (20,0,0,0))\n",
    "fig_rmse_cp_t3.background_fill_color=None\n",
    "fig_f1_cp_t3.background_fill_color=None\n",
    "fig_mae_cp_t3.background_fill_color=None\n",
    "\n",
    "glyph_s1 = Label(x=50, y=cp_width/2, x_units = 'screen', y_units = 'screen', text=\"First segment\", text_color = '#36B33F')\n",
    "glyph_s2 = Label(x=50, y=cp_width/2-20, x_units = 'screen', y_units = 'screen', text=\"Second segment\", text_color = '#1294B3')\n",
    "for g in [glyph_s1, glyph_s2]:\n",
    "    fig_mae_cp_t3.add_layout(g)\n",
    "\n",
    "cp_figures(fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3)\n",
    "\n",
    "for fig in [fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3]:\n",
    "    fig.xaxis.major_label_orientation = np.pi/4\n",
    "\n",
    "# Updates\n",
    "for control in [dim_select_t3, team_select_t3]:\n",
    "    control.on_change('value', lambda attr, old, new: update_t3())\n",
    "    \n",
    "cp_slider_t3.on_change('value_throttled', lambda attr, old, new: update_t3())\n",
    "\n",
    "for control in [model1_group_t3, model2_group_t3]:\n",
    "    control.on_change('value', lambda attr, old, new: update_t3_mod())\n",
    "    \n",
    "for control in [alpha1_slider_t3, alpha2_slider_t3]:\n",
    "    control.on_change('value_throttled', lambda attr, old, new: update_t3_alpha())\n",
    "    \n",
    "\n",
    "def update_select_team_t3(attrname, old, new):    \n",
    "    team_select_t3.options = np.unique([n[:-3] for n in df_t3[dims.index(dim_select_t3.value)].keys()[6:]]).tolist() \n",
    "    team_select_t3.value = team_select_t3.options[0]\n",
    "    update_t3()\n",
    "    \n",
    "dim_select_t3.on_change('value', update_select_team_t3)\n",
    "\n",
    "inputs = column(dim_select_t3,\n",
    "                team_select_t3,                \n",
    "                row(model1_group_t3, model2_group_t3, width = 220),\n",
    "                cp_slider_t3,\n",
    "                alpha1_slider_t3,\n",
    "                alpha2_slider_t3,\n",
    "                div_t3_aux, width = 220)\n",
    "    \n",
    "col_rmse = column(fig_rmse_mod_t3, fig_rmse_alpha_t3)\n",
    "col_cp = column(fig_rmse_cp_t3, fig_mae_cp_t3, fig_f1_cp_t3)\n",
    "\n",
    "l3 = grid([div_t3, \n",
    "           row(inputs, col_rmse, col_cp)])\n",
    "\n",
    "if notebook:\n",
    "    def modify_doc(doc):\n",
    "        doc.add_root(row(l3, width=10))\n",
    "\n",
    "    handler = FunctionHandler(modify_doc)\n",
    "    app = Application(handler)\n",
    "    show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "tab_main = Panel(child = layout_main, title = 'Challenge Summary')\n",
    "tab1 = Panel(child=l1,title=\"Task 1\")\n",
    "tab2 = Panel(child=l2,title=\"Task 2\")\n",
    "tab3 = Panel(child=l3,title=\"Task 3\")\n",
    "tab4 = Panel(child=lnew,title=\"New submission\")\n",
    "\n",
    "layout = Tabs(tabs=[tab_main, tab1, tab2, tab3, tab4])\n",
    "\n",
    "if notebook:\n",
    "    def modify_doc(doc):\n",
    "        doc.add_root(row(layout, width=10))\n",
    "\n",
    "    handler = FunctionHandler(modify_doc)\n",
    "    app = Application(handler)\n",
    "    show(app)\n",
    "\n",
    "# For export\n",
    "curdoc().add_root(row(layout, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
